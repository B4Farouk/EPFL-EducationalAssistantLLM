{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_path: str, device: torch.device):    \n",
    "    config = PeftConfig.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
    "    model = PeftModel.from_pretrained(model, model_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "    return model, tokenizer\n",
    "def load_transform_prompts(filename: str):\n",
    "    with open(filename, \"rb\") as reader:\n",
    "        data = json.load(reader)\n",
    "\n",
    "    def mcq_assembler(question, choices):\n",
    "        for i, choice in enumerate(choices):\n",
    "            question += f\"\\n{i+1}) {choice}\"\n",
    "        return question\n",
    "                \n",
    "    def assemble_prompt(datum):\n",
    "        is_mcq = datum.get(\"choices\", None) is not None\n",
    "        question = mcq_assembler(datum[\"question\"], datum[\"choices\"]) if is_mcq\\\n",
    "            else datum[\"question\"]\n",
    "        return f\"Question: {question} Answer:\"\n",
    "        \n",
    "    prompts = [(datum[\"guid\"], assemble_prompt(datum)) for datum in data]\n",
    "    return prompts\n",
    "\n",
    "def batch_generate(model, tokenizer, prompts, gen_config):\n",
    "\n",
    "    # batch tokenization    \n",
    "    encs = tokenizer.batch_encode_plus(prompts,\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    max_length=tokenizer.model_max_length,\n",
    "                    return_tensors=\"pt\")\n",
    "\n",
    "    encs = {k:v.to(model.device) for k,v in encs.items()}\n",
    "    \n",
    "    # gen config\n",
    "    gen_config = deepcopy(gen_config)\n",
    "    \n",
    "    # generation\n",
    "    generations = model.generate(**encs, **gen_config)\n",
    "    return generations\n",
    "def print_answer(text, n=15):\n",
    "    print(\"\\n\".join([\" \".join(text.split()[i:i+n]) for i in range(0, len(text.split()), n)]))\n",
    "\n",
    "def gen_answer_with_guid(prompts, model, tokenizer, gen_config, guid):\n",
    "    batch = [datum for datum in prompts if datum[0] == guid]\n",
    "    print_answer(batch[0][1])\n",
    "    guids, prompts = zip(*batch)\n",
    "    generations = batch_generate(model, tokenizer, prompts, gen_config)\n",
    "    generations = [tokenizer.decode(gen, skip_special_tokens=True) for gen in generations]\n",
    "    print_answer(generations[0])\n",
    "\n",
    "def gen_answer(text, model, tokenizer, gen_config):\n",
    "    print_answer(text)\n",
    "    generations = batch_generate(model, tokenizer, [text], gen_config)\n",
    "    generations = [tokenizer.decode(gen, skip_special_tokens=True) for gen in generations]\n",
    "    print_answer(generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_with_guids = load_transform_prompts(\"../../../prompts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"../../models/t5-finetuned/t5-base\", torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gen_config = {\n",
    "    # general\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"min_length\": 16,\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    # sampling\n",
    "    \"top_k\": 0,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.3,\n",
    "    \n",
    "    # against repetition\n",
    "    \"no_repeat_ngram_size\": 4,\n",
    "    \"repetition_penalty\": 1.5,\n",
    "    \n",
    "    # speed-up\n",
    "    \"use_cache\": True \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# select a guids\u001b[39;00m\n\u001b[0;32m      5\u001b[0m guid_selected \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb82db1db-a6f9-4e3a-8d45-9a89cfddd953\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"b82db1db-a6f9-4e3a-8d45-9a89cfddd953\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the difference between genetics and epigenetics? 1) Genetic characteristics are heritable, but\n",
      "not epigenetic one 2) Epigenetic characteristics vary between cell types, but genetic characteristics do not\n",
      "3) Differences in epigenetics do not influence gene expression whereas genetic variability does 4) All\n",
      "of the above Answer:\n",
      "The correct answer is 4) All of the above. Genetic characteristics are heritable, but not\n",
      "epigenetic one. Genetic characteristics vary between cell types, but genetic characteristics do not influence gene\n",
      "expression whereas genetic variability does. Epigenetic characteristics vary between cells types, but gene characteristics do\n",
      "not. Genetic characteristics do not affect gene expression, but they do influence gene expression. Therefore,\n",
      "the correct answer is 2) Epigenetic traits vary between cell type, but genetic traits do\n",
      "not.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"1986353f-b780-4b31-94d6-fd9af077fb07\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Sometimes, in Cl plasma etching, a corrosion phenomenon is observed in Al etching under\n",
      "the form of chlorine-containing residues remaining on the film sidewalls. Which of the following is\n",
      "a correct approach to avoid this problem? 1) Immersing the wafer in a PGMEA developer\n",
      "2) Gently blowing the wafer surface with nitrogen gun to create AlN gas 3) Dipping\n",
      "before etching the wafer in diluted acetone solution 4) Exposing the etched structure to a\n",
      "fluorine plasma immediately after the Cl plasma Answer:\n",
      "To avoid corrosion, we should first isolate the etching process and then apply a fluorine\n",
      "solution to the surface of the wafer. This will allow the etcher to create a\n",
      "fluoride solution that can be applied directly to the surface. Then, we can use a\n",
      "fluorosin solution to remove the chlorine-containing residues on the film sidewalls. The solution will be\n",
      "diluted to produce a fluoresine solution and then etched into the wafer to allow it\n",
      "to react with the etch material.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"88379c2b-4bda-41c0-b1c1-e44dc19ea14b\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer:\n",
      "I would suggest that the team should organize daily Scrum meetings to discuss the progress\n",
      "of the tasks and how to implement complex features. This will help them understand the\n",
      "process and the goals of the project, and will also provide feedback on the implementation\n",
      "of the feature.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"bee98e82-357d-4d86-8c63-2f4c36b56e3f\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"../../models/t5-finetuned/t5-large\", torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gen_config = {\n",
    "    # general\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"min_length\": 16,\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    # sampling\n",
    "    \"top_k\": 0,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.3,\n",
    "    \n",
    "    # against repetition\n",
    "    \"no_repeat_ngram_size\": 4,\n",
    "    \"repetition_penalty\": 1.5,\n",
    "    \n",
    "    # speed-up\n",
    "    \"use_cache\": True \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are using a 3-layer fully-connected neural, and you are using \\textbf{$f(x) = 2x$\n",
      "as your activation function} . Your input data has components in [0, 1]. \\textbf{You initialize\n",
      "your weights using Kaiming (He) initialization}, and set all the bias terms to 0. You\n",
      "start optimizing using SGD. What will likely happen? 1) The gradient is 0 so nothing\n",
      "happens 2) The gradient is very large so the model can't converge 3) Training is\n",
      "fine, but our neural net does only as well as a linear model 4) Everything\n",
      "is fine Answer:\n",
      "The correct answer is 4) Everything is fine. In this case, the gradient is very\n",
      "large so the model can't converge. This is because the gradient is not a function\n",
      "of the input data, but rather a function that represents the weights and bias terms\n",
      "of the neural network. Therefore, the gradient will be very large and the model will\n",
      "not be able to converge.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"b82db1db-a6f9-4e3a-8d45-9a89cfddd953\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the difference between genetics and epigenetics? 1) Genetic characteristics are heritable, but\n",
      "not epigenetic one 2) Epigenetic characteristics vary between cell types, but genetic characteristics do not\n",
      "3) Differences in epigenetics do not influence gene expression whereas genetic variability does 4) All\n",
      "of the above Answer:\n",
      "The correct answer is 4) All of the above. Genetic characteristics are heritable, but not\n",
      "epigenetic one. This is because genetic traits are passed down from parents to offspring through\n",
      "DNA replication and gene expression. Epigenetic characteristics vary between cell types, but genetic characteristics do\n",
      "not. Therefore, options 1 and 2 are incorrect. Option 3 is also incorrect.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"1986353f-b780-4b31-94d6-fd9af077fb07\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Sometimes, in Cl plasma etching, a corrosion phenomenon is observed in Al etching under\n",
      "the form of chlorine-containing residues remaining on the film sidewalls. Which of the following is\n",
      "a correct approach to avoid this problem? 1) Immersing the wafer in a PGMEA developer\n",
      "2) Gently blowing the wafer surface with nitrogen gun to create AlN gas 3) Dipping\n",
      "before etching the wafer in diluted acetone solution 4) Exposing the etched structure to a\n",
      "fluorine plasma immediately after the Cl plasma Answer:\n",
      "The correct approach to avoid corrosion phenomenon in Al etching is 1) Immersing the wafer\n",
      "in a PGMEA developer. This method involves immersing the film in a solution of PGMEAA,\n",
      "which can be used for etching in Cl plasma. However, it may not be suitable\n",
      "for Al etch because it may leave residues on the film sidewalls. 2) Gently blowing\n",
      "the waffer surface with nitrogen gun to create AlN gas. This method does not provide\n",
      "any protection against corrosion, and it may cause a corrosion reaction. 3) Dipping before etching\n",
      "the wader in diluted acetone solution. This method is not recommended for Al etched films,\n",
      "as it may result in a corrosion problem. 4) Exposing the etched structure to a\n",
      "fluorine plasma immediately after the Cl plasma. This method can help prevent corrosion, but it\n",
      "may not completely eliminate the corrosion problem.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"88379c2b-4bda-41c0-b1c1-e44dc19ea14b\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer:\n",
      "I would suggest that the team should organize daily Scrum meetings to discuss the progress\n",
      "of the tasks and how to implement complex features. This will help to ensure that\n",
      "the team is on track and that they are not stalling on the task or\n",
      "feature that they are working on.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"bee98e82-357d-4d86-8c63-2f4c36b56e3f\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-base PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"../../models/t5-base-finetuned-ppo/full-training\", torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gen_config = {\n",
    "    # general\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"min_length\": 16,\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    # sampling\n",
    "    \"top_k\": 0,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.3,\n",
    "    \n",
    "    # against repetition\n",
    "    \"no_repeat_ngram_size\": 4,\n",
    "    \"repetition_penalty\": 1.5,\n",
    "    \n",
    "    # speed-up\n",
    "    \"use_cache\": True \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are using a 3-layer fully-connected neural, and you are using \\textbf{$f(x) = 2x$\n",
      "as your activation function} . Your input data has components in [0, 1]. \\textbf{You initialize\n",
      "your weights using Kaiming (He) initialization}, and set all the bias terms to 0. You\n",
      "start optimizing using SGD. What will likely happen? 1) The gradient is 0 so nothing\n",
      "happens 2) The gradient is very large so the model can't converge 3) Training is\n",
      "fine, but our neural net does only as well as a linear model 4) Everything\n",
      "is fine Answer:\n",
      "The correct answer is: 1). The gradient is 0 so nothing happens.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"b82db1db-a6f9-4e3a-8d45-9a89cfddd953\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the difference between genetics and epigenetics? 1) Genetic characteristics are heritable, but\n",
      "not epigenetic one 2) Epigenetic characteristics vary between cell types, but genetic characteristics do not\n",
      "3) Differences in epigenetics do not influence gene expression whereas genetic variability does 4) All\n",
      "of the above Answer:\n",
      "The correct answer is: 1). Genetic characteristics are heritable, but not epigenetic one.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"1986353f-b780-4b31-94d6-fd9af077fb07\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Sometimes, in Cl plasma etching, a corrosion phenomenon is observed in Al etching under\n",
      "the form of chlorine-containing residues remaining on the film sidewalls. Which of the following is\n",
      "a correct approach to avoid this problem? 1) Immersing the wafer in a PGMEA developer\n",
      "2) Gently blowing the wafer surface with nitrogen gun to create AlN gas 3) Dipping\n",
      "before etching the wafer in diluted acetone solution 4) Exposing the etched structure to a\n",
      "fluorine plasma immediately after the Cl plasma Answer:\n",
      "To avoid this problem, we can use a PGMEA developer.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"88379c2b-4bda-41c0-b1c1-e44dc19ea14b\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer:\n",
      "I would like to discuss the implementation of a feature that will allow users to\n",
      "scan a QR code to get a discount.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"bee98e82-357d-4d86-8c63-2f4c36b56e3f\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt2 large\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_gen_config = {\n",
    "    # general\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"min_length\": 16,\n",
    "    \"max_length\": 512,\n",
    "    \n",
    "    # sampling\n",
    "    \"top_k\": 0,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.3,\n",
    "    \n",
    "    # against repetition\n",
    "    \"no_repeat_ngram_size\": 4,\n",
    "    \"repetition_penalty\": 1.5,\n",
    "    \n",
    "    # speed-up\n",
    "    \"use_cache\": True \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: You are using a 3-layer fully-connected neural, and you are using \\textbf{$f(x) = 2x$\n",
      "as your activation function} . Your input data has components in [0, 1]. \\textbf{You initialize\n",
      "your weights using Kaiming (He) initialization}, and set all the bias terms to 0. You\n",
      "start optimizing using SGD. What will likely happen? 1) The gradient is 0 so nothing\n",
      "happens 2) The gradient is very large so the model can't converge 3) Training is\n",
      "fine, but our neural net does only as well as a linear model 4) Everything\n",
      "is fine Answer:\n",
      "Question: You are using a 3-layer fully-connected neural, and you are using \\textbf{$f(x) = 2x$\n",
      "as your activation function}. Your input data has components in [0, 1]. \\textbf{You initialize your\n",
      "weights using Kaiming (He) initialization}, and set all the bias terms to 0. You start\n",
      "optimizing using SGD. What will likely happen? 1) The gradient is 0 so nothing happens\n",
      "2) The gradient is very large so the model can't converge 3) Training is fine,\n",
      "but our neural net does only as well as a linear model 4) Everything is\n",
      "fine Answer: We have already seen that if we use an LSTM for training then\n",
      "it should be able to learn from its own mistakes! So let's try this again\n",
      "with some more parameters. First of all I'll define my network architecture by adding another\n",
      "layer on top of each other. This time instead of just two layers there would\n",
      "now be four layers stacked one above the next - which means they could overlap\n",
      "at any point during their learning process. If we were going to do something like\n",
      "this for every single parameter we'd need around 8 different configurations per neuron or about\n",
      "10 million neurons total. But since we're not doing anything fancy here, lets keep things\n",
      "simple and stick to what works best. Let me show how this might look like\n",
      "after applying these changes to our previous example dataset. In order to get good results\n",
      "when trying out new architectures we must first understand exactly why those models work better\n",
      "than others. To begin with, consider the following graph where $y_i=\\frac{\\partial y}{\\partial x}\\sum_{j=1..n+k>0}}^{{\\left(\\begin{array}{ccc}a & b\n",
      "\\\\ c & d\\\\ e& f)\\right)}^{N/m}.$$ Here $\\mathcal {L}$ represents the number of hidden units\n",
      "in the unit cell. Each node corresponds to either \\(b\\) or \\(d\\) depending upon whether\n",
      "or not the current state contains information relating to the given value. For instance, suppose\n",
      "that the output states \"A\" and \"B\". Then the nodes corresponding to both values represent\n",
      "\\(e\\) and \\(g'. Since \\(h\\) indicates that the current state includes knowledge related to the\n",
      "former value, the nodes representing \\(e'\\) and \\( g''') correspond respectively to \\(e', h'). Now\n",
      "imagine that we want to train a classifier based solely on\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"b82db1db-a6f9-4e3a-8d45-9a89cfddd953\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the difference between genetics and epigenetics? 1) Genetic characteristics are heritable, but\n",
      "not epigenetic one 2) Epigenetic characteristics vary between cell types, but genetic characteristics do not\n",
      "3) Differences in epigenetics do not influence gene expression whereas genetic variability does 4) All\n",
      "of the above Answer:\n",
      "Question: What is the difference between genetics and epigenetics? 1) Genetic characteristics are heritable, but\n",
      "not epigenetic one 2) Epigenetic characteristics vary between cell types, but genetic characteristics do not\n",
      "3) Differences in epigenetics do not influence gene expression whereas genetic variability does 4) All\n",
      "of the above Answer: The answer to this question depends on what you mean by\n",
      "\"genes\" or \"epitopes\". In a nutshell, genes determine how an organism develops. These include DNA\n",
      "(the blueprint for life), RNA (which carries instructions that can be read from outside the\n",
      "genome into cells) and proteins which carry out specific functions such as protein synthesis, repair\n",
      "etc.. This means that if we know something about human development then it will also\n",
      "tell us whether our children have certain traits like height or intelligence. However there's more\n",
      "than just these two things; other factors may play a role too - including environmental\n",
      "influences, diet/nutrition, stress levels etc... So when looking at all those variables together they add\n",
      "up to make a person who has particular attributes. For example, having high IQs might\n",
      "lead someone with low self-esteem to become depressed because he feels so worthless compared to\n",
      "others around him. Or maybe being overweight leads people to feel insecure and anxious due\n",
      "to their appearance. It could even explain why some women prefer men whose bodies look\n",
      "similar to theirs while others find them unattractive! A good way to think about your\n",
      "own personal preferences would be to ask yourself 'what kind of man am I?' If\n",
      "you answered male, chances are you're probably going to want a tall guy. But what\n",
      "happens when you start thinking about how different heights affect personality? Well let me give\n",
      "you another hypothetical scenario. Imagine you've been dating for years now and finally decide to\n",
      "get married. You both love each other very much and plan everything carefully before getting\n",
      "down to business. One day whilst walking through town you notice a girl standing next\n",
      "to you wearing short shorts and flip flops. She looks pretty hot though doesn't she?!\n",
      "Then suddenly you realise that she isn't really dressed well either – she seems quite\n",
      "skinny despite her size. And yet somehow she manages to stand out amongst everyone else.\n",
      "Why did she choose to wear such skimpy clothing? Did she expect anyone to see\n",
      "her naked body? Was she trying to attract attention? Maybe she was worried about attracting\n",
      "unwanted attention from guys nearby… Perhaps she thought that since most girls were slim and\n",
      "beautiful enough already she'd never need anything extra. Whatever the reason, you don\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"1986353f-b780-4b31-94d6-fd9af077fb07\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Sometimes, in Cl plasma etching, a corrosion phenomenon is observed in Al etching under\n",
      "the form of chlorine-containing residues remaining on the film sidewalls. Which of the following is\n",
      "a correct approach to avoid this problem? 1) Immersing the wafer in a PGMEA developer\n",
      "2) Gently blowing the wafer surface with nitrogen gun to create AlN gas 3) Dipping\n",
      "before etching the wafer in diluted acetone solution 4) Exposing the etched structure to a\n",
      "fluorine plasma immediately after the Cl plasma Answer:\n",
      "Question: Sometimes, in Cl plasma etching, a corrosion phenomenon is observed in Al etching under\n",
      "the form of chlorine-containing residues remaining on the film sidewalls. Which of the following is\n",
      "a correct approach to avoid this problem? 1) Immersing the wafer in a PGMEA developer\n",
      "2) Gently blowing the wafer surface with nitrogen gun to create AlN gas 3) Dipping\n",
      "before etching the wafer in diluted acetone solution 4) Exposing the etched structure to a\n",
      "fluorine plasma immediately after the Cl plasma Answer: 1). The first option would be an\n",
      "obvious choice for most applications and should not cause any problems at all. However, if\n",
      "you are using it as part of your process or plan to do so then\n",
      "I suggest that you consider another method (see below), which will allow you to control\n",
      "how much fluoride ions remain on the exposed substrate during subsequent steps without having to\n",
      "worry about damaging the underlying substrate. 2). This may seem like overkill but there have\n",
      "been some reports where people were able to use this technique successfully when they used\n",
      "other methods such as gassing instead of exposing the material directly to air. 3). It's\n",
      "possible that some types of aluminum can become contaminated by excess chloride ion concentration from\n",
      "the nitric acid reaction. In these cases, one could try spraying them down with water\n",
      "prior to exposure. 4). If you're going to expose the metal to high concentrations of\n",
      "chlorination chemical(s) while doing step 5 above, make sure that you don't leave anything behind!\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"88379c2b-4bda-41c0-b1c1-e44dc19ea14b\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer:\n",
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer: I think it's great! It is very important for us as\n",
      "developers in our teams to be able to communicate with each other about what we're\n",
      "working on so everyone can have an idea where they stand at any given time.\n",
      "The best way to do this is by having regular weekly or monthly scrum sessions\n",
      "(or even more frequently if needed). If there isn't enough communication between members then people\n",
      "tend not to know which direction their work needs to go next; instead they end\n",
      "up doing things just because someone else said \"do\" rather than thinking through why something\n",
      "might need improvement. This leads to poor product development quality, less collaboration among teammates, etc.,\n",
      "all problems that could easily become bigger issues once implemented into production. Q: How much\n",
      "does planning matter when designing new products/services? Do you feel that designers often neglect planning\n",
      "altogether? Or maybe design has been over-emphasized lately? Answers: Planning matters greatly but sometimes too\n",
      "little. Designers must take care to make sure that every aspect of the project fits\n",
      "together well before starting coding. They also need to consider whether certain aspects require additional\n",
      "effort beyond those already planned out beforehand. For example, if one designer decides he doesn't\n",
      "want to add another layer onto his existing UI component, others may decide against adding\n",
      "anything further until such time as they see fit. In addition, many times designers don't\n",
      "really understand the complexity involved in implementing specific functionality – afterall, most software projects involve\n",
      "multiple layers of abstraction. So while planning certainly helps ensure that everything works properly, it\n",
      "shouldn't replace actual programming skills. As far as redesigning goes, I'd say that it depends\n",
      "entirely upon who designs the changes and what kind of feedback they receive during these\n",
      "discussions. Some companies try to avoid reworking old ideas completely since they believe that the\n",
      "current version won't hold up under scrutiny anyway. Others simply accept whatever comes along without\n",
      "trying hard to change them. Either way, though, it seems pretty clear that good design\n",
      "makes a big difference in terms of keeping things fresh throughout the life cycle of\n",
      "a particular application.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"bee98e82-357d-4d86-8c63-2f4c36b56e3f\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Question: What are some advantages of using AODs vs scanning\n",
    "mirrors for OT positioning? Answer: One advantage of using acousto-\n",
    "optic deflectors (AODs) for optical tweezers (OT) positioning is that\n",
    "they have faster response times than scanning mirrors. This allows for\n",
    "more precise and rapid manipulation of particles or cells. Additionally,\n",
    "AODs do not suffer from mechanical wear and tear like scanning mirrors,\n",
    "resulting in improved long-term stability and reliability. AODs also have\n",
    "a larger deflection angle compared to scanning mirrors, enabling larger\n",
    "field-of-view and larger displacement ranges. Finally, AODs are relatively\n",
    "compact and can be easily integrated into existing microscope setups.\n",
    "Question: So, from the following options, which option would you choose\n",
    "as the answer to the question above: A. faster movements B. lower losses\n",
    "C. more uniform field D. larger range of movements Answer: The answer\n",
    "to the question is ”D. larger range of movements.” Question: There might\n",
    "be more than one correct options, is there any other option that also\n",
    "answer the question above, explain why? Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are some advantages of using AODs vs scanning mirrors for OT positioning? Answer:\n",
      "One advantage of using acousto- optic deflectors (AODs) for optical tweezers (OT) positioning is that\n",
      "they have faster response times than scanning mirrors. This allows for more precise and rapid\n",
      "manipulation of particles or cells. Additionally, AODs do not suffer from mechanical wear and tear\n",
      "like scanning mirrors, resulting in improved long-term stability and reliability. AODs also have a larger\n",
      "deflection angle compared to scanning mirrors, enabling larger field-of-view and larger displacement ranges. Finally, AODs\n",
      "are relatively compact and can be easily integrated into existing microscope setups. Question: So, from\n",
      "the following options, which option would you choose as the answer to the question above:\n",
      "A. faster movements B. lower losses C. more uniform field D. larger range of movements\n",
      "Answer: The answer to the question is ”D. larger range of movements.” Question: There might\n",
      "be more than one correct options, is there any other option that also answer the\n",
      "question above, explain why? Answer:\n",
      "A. The correct option is ”D. larger range of movements.” This option is correct because\n",
      "AODs have a larger deflection angle compared to scanning mirrors, enabling larger field-of-view and larger\n",
      "displacement ranges. This allows for more precise and rapid manipulation of particles or cells. Furthermore,\n",
      "AODs also have a more uniform field compared to scanners, allowing larger field-off-view and greater\n",
      "displacement ranges, making them more efficient and easy to integrate into existing microscope setups.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "gen_answer(question, model, tokenizer, default_gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer:\n",
      "I would suggest that the team should organize daily Scrum meetings to discuss the progress\n",
      "of the tasks and how to implement complex features. This will help to ensure that\n",
      "the team is on track and that they are not stalling on the task or\n",
      "feature that they are working on.\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# select a guids\n",
    "guid_selected = \"bee98e82-357d-4d86-8c63-2f4c36b56e3f\"\n",
    "\n",
    "gen_answer_with_guid(prompts_with_guids, model, tokenizer, default_gen_config, guid_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
      "to discuss the progress of the tasks and how to implement complex features. This will\n",
      "help to ensure that the team is on track and that they are not stalling\n",
      "on the task or feature that they are working on. Question: Are you sure that\n",
      "complex features should be discussed here ? Answer:\n",
      "I am sure that the team should discuss complex features in daily Scrum meetings. This\n",
      "will help to ensure that the team is on track and that they are not\n",
      "stalling on the task or feature that they are working on.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
    "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
    "the progress of the tasks and how to implement complex features. He especially wants to\n",
    "discuss the implementation of a feature that will allow users to scan a QR code\n",
    "to get a discount, and would like some input from the team. What are your\n",
    "thoughts on this? Answer:\n",
    "I would suggest that the team should organize daily Scrum meetings to discuss the progress\n",
    "of the tasks and how to implement complex features. This will help to ensure that\n",
    "the team is on track and that they are not stalling on the task or\n",
    "feature that they are working on. Question: Are you sure that complex features should be discussed here ? Answer:\n",
    "\"\"\"\n",
    "gen_answer(question, model, tokenizer, default_gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
      "to discuss the progress of the tasks and how to implement complex features. This will\n",
      "help to ensure that the team is on track and that they are not stalling\n",
      "on the task or feature that they are working on. Question: Are you sure that\n",
      "complex features should be discussed here ? Answer: I am sure that the team should\n",
      "discuss complex features in daily Scrum meetings. This will help to ensure that the team\n",
      "is on track and that they are not stalling on the task or feature that\n",
      "they are working on. Question: What is Scrum ? Answer:\n",
      "Scrum is a process for managing and coordinating the work of a team. It is\n",
      "a method used by agile software development methodologies to manage the flow of work and\n",
      "ensure that each team member contributes to the overall project.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"\n",
    "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
    "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
    "the progress of the tasks and how to implement complex features. He especially wants to\n",
    "discuss the implementation of a feature that will allow users to scan a QR code\n",
    "to get a discount, and would like some input from the team. What are your\n",
    "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
    "to discuss the progress of the tasks and how to implement complex features. This will\n",
    "help to ensure that the team is on track and that they are not stalling\n",
    "on the task or feature that they are working on. Question: Are you sure that\n",
    "complex features should be discussed here ? Answer:\n",
    "I am sure that the team should discuss complex features in daily Scrum meetings. This\n",
    "will help to ensure that the team is on track and that they are not\n",
    "stalling on the task or feature that they are working on. Question: What is Scrum ? Answer:\n",
    "\"\"\"\n",
    "gen_answer(question, model, tokenizer, default_gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
      "to discuss the progress of the tasks and how to implement complex features. This will\n",
      "help to ensure that the team is on track and that they are not stalling\n",
      "on the task or feature that they are working on. Question: Are you sure that\n",
      "complex features should be discussed here ? Answer: I am sure that the team should\n",
      "discuss complex features in daily Scrum meetings. This will help to ensure that the team\n",
      "is on track and that they are not stalling on the task or feature that\n",
      "they are working on. Question: What is Scrum ? Answer: Scrum is a process for\n",
      "managing and coordinating the work of a team. It is a method used by agile\n",
      "software development methodologies to manage the flow of work and ensure that each team member\n",
      "contributes to the overall project. Question: Can you explain your first answer by taking into\n",
      "account the definition of scrum ? Answer:\n",
      "To explain my first answer, I would need to take into account the definition of\n",
      "Scrum. Scrum is a process for managing and coordinating the work of a team. It\n",
      "is a method used by agile software development methodologies to manage the flow of work\n",
      "and ensure that each team member contributes to the overall project. The definition of Scum\n",
      "includes: \"An activity that involves a set of tasks or activities that are completed in\n",
      "a specific sequence, typically within a time period of several days.\" This means that the\n",
      "process can be divided into two phases: \"Process\" and \"End\". In Scrum, the process is\n",
      "structured in a way that allows each team member to participate in the process and\n",
      "contribute to the overall product. This means that each team has a defined role in\n",
      "the process, and each team member has a role in the delivery of the product.\n",
      "Therefore, the process of Scrum can be divided between two phases: Process and End. Process:\n",
      "This phase is where the team members work together to complete a task or feature\n",
      "that they have been working on. End: This phase involves the completion of the project\n",
      "and the release of the product to the market. End: The process is structured around\n",
      "a series of steps that are completed before the product is released to the public.\n",
      "These steps include: \"Conceptualization\", \"Design\", \"Finance\", \"User Acceptance\", \"Operation\", \"Review\", and \"Support\". This phase is\n",
      "typically completed by the end of the project. Implementation: This phase includes the finalization of\n",
      "the product and its integration with the user's existing system. This phase is usually completed\n",
      "by the release of a new version of the product or service.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
    "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
    "the progress of the tasks and how to implement complex features. He especially wants to\n",
    "discuss the implementation of a feature that will allow users to scan a QR code\n",
    "to get a discount, and would like some input from the team. What are your\n",
    "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
    "to discuss the progress of the tasks and how to implement complex features. This will\n",
    "help to ensure that the team is on track and that they are not stalling\n",
    "on the task or feature that they are working on. Question: Are you sure that\n",
    "complex features should be discussed here ? Answer: I am sure that the team should\n",
    "discuss complex features in daily Scrum meetings. This will help to ensure that the team\n",
    "is on track and that they are not stalling on the task or feature that\n",
    "they are working on. Question: What is Scrum ? Answer:\n",
    "Scrum is a process for managing and coordinating the work of a team. It is\n",
    "a method used by agile software development methodologies to manage the flow of work and\n",
    "ensure that each team member contributes to the overall project. Question: Can you explain your first answer\n",
    "by taking into account the definition of scrum ? Answer:\n",
    "\"\"\"\n",
    "gen_answer(question, model, tokenizer, default_gen_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
      "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
      "the progress of the tasks and how to implement complex features. He especially wants to\n",
      "discuss the implementation of a feature that will allow users to scan a QR code\n",
      "to get a discount, and would like some input from the team. What are your\n",
      "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
      "to discuss the progress of the tasks and how to implement complex features. This will\n",
      "help to ensure that the team is on track and that they are not stalling\n",
      "on the task or feature that they are working on. Question: Can you explain in\n",
      "in more details what Scrum is and explain more your answer to the previous question\n",
      "by taking the definition into account ? Answer:\n",
      "Scrum is a process that is used to define and implement a set of tasks\n",
      "and features that are required to achieve a specific outcome. It is a framework for\n",
      "identifying, developing, and implementing new features and features that can be implemented in a specific\n",
      "way. It is also a framework to ensure that the team is on track and\n",
      "that they are not stalling on the task or feature that they are working on.\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\"Question: Assume that you are part of a team developing a mobile app using Scrum.\n",
    "One of your colleagues suggests that your team should organize daily Scrum meetings to discuss\n",
    "the progress of the tasks and how to implement complex features. He especially wants to\n",
    "discuss the implementation of a feature that will allow users to scan a QR code\n",
    "to get a discount, and would like some input from the team. What are your\n",
    "thoughts on this? Answer: I would suggest that the team should organize daily Scrum meetings\n",
    "to discuss the progress of the tasks and how to implement complex features. This will\n",
    "help to ensure that the team is on track and that they are not stalling\n",
    "on the task or feature that they are working on. Question: Can you explain in in more details\n",
    "what Scrum is and explain more your answer to the previous question by taking the definition into account ? Answer:\n",
    "\"\"\"\n",
    "gen_answer(question, model, tokenizer, default_gen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
