{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ARCPH_bFVKJ",
        "outputId": "2c517ee5-8df6-42ce-8506-9a5eb18246cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beof3LP9FVDK",
        "outputId": "5680551c-98dd-48a1-9597-1dd903c1a5d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/project-m3-notanagi/notebooks/sft_training\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/project-m3-notanagi/notebooks/sft_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QfJT_VBFSHJ",
        "outputId": "ccd2d854-bf52-418b-ac24-ed3dae542955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.39.0-py3-none-any.whl (92.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.39.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-ek8wzumk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ek8wzumk\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 0d217f428fa5b84fcde9c31ef1c95e4215856f7e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.31.0.dev0)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0.dev0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.31.0.dev0)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0.dev0) (3.4)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.31.0.dev0-py3-none-any.whl size=7170396 sha256=ef0416d355e2d880624f95a0046eebbe92550f4d090d7cdb00780e4157b7f65c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q_qblicv/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0.dev0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/peft.git\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-jznxmwpi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-jznxmwpi\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 189a6b8e357ecda05ccde13999e4c35759596a67\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (6.0)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (4.31.0.dev0)\n",
            "Collecting accelerate (from peft==0.4.0.dev0)\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.4.0.dev0) (0.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.4.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0.dev0) (16.0.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (0.15.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.4.0.dev0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0.dev0) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.4.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.4.0.dev0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.4.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: peft\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=59308 sha256=e5db66ad8e29e914e16dca60b9c5f70afac412c6558edd8b20d3c4262aaaa5da\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-34oy545d/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "Successfully built peft\n",
            "Installing collected packages: accelerate, peft\n",
            "Successfully installed accelerate-0.20.3 peft-0.4.0.dev0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/accelerate.git\n",
            "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-5qgstuqy\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-5qgstuqy\n",
            "  Resolved https://github.com/huggingface/accelerate.git to commit 665d5180fcc01d5700f7a9aa3f9bdb75c6055dce\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.21.0.dev0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.21.0.dev0) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.21.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.21.0.dev0) (1.3.0)\n",
            "Building wheels for collected packages: accelerate\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for accelerate: filename=accelerate-0.21.0.dev0-py3-none-any.whl size=228089 sha256=85acf12d7f2339281c836b4b077a8c834875b1a605ef662b4d92ef51601b6ed0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a0jhbhbp/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n",
            "Successfully built accelerate\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.20.3\n",
            "    Uninstalling accelerate-0.20.3:\n",
            "      Successfully uninstalled accelerate-0.20.3\n",
            "Successfully installed accelerate-0.21.0.dev0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U git+https://github.com/huggingface/transformers.git \n",
        "!pip install -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zSUEm4IFSHM",
        "outputId": "8722112f-e2ea-4699-e235-4b1dd58beb1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 118\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('8013'), PosixPath('http'), PosixPath('//172.28.0.1')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-wo8skrc8msxu --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true'), PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
            "Either way, this might cause trouble in the future:\n",
            "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
            "  warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "MODULE_PATHS = [\"../../modules\"]\n",
        "for module_path in MODULE_PATHS:\n",
        "    if module_path not in sys.path:\n",
        "        sys.path.append(module_path)\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "import torch\n",
        "from fine_tuning import build_finetuning_hf_dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments\n",
        "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
        "from datasets import load_dataset\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iLAt_CxdFSHM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "673a38af197d4e55834054b30e7951e1",
            "3559b4ddfd7d4b36be55ec7e702c5c08",
            "2d380eda51b043ffaf301a35e1da58fe",
            "f969c4036f0742b3b0cff48745bb2dcf",
            "348c6c5e39604ce3b7cb51fa4b470b3c",
            "3c3c6a84c19b427b87354271e2cf00d1",
            "27df17739ce34e64ba8602a304f2d9f7",
            "a5112f897a4c48e0836c3bf395903d8b",
            "d1145526d0054c9c9ea9c43c208d031d",
            "f3497af9c7474a778218a09a9249f067",
            "67538ed127274e6abe72780cd1e56820",
            "a716c640869749cb85103cf50421a19a",
            "447bd8184fe94fcab2f8971e2277b394",
            "c2b14b0fdc7a41c498a70a2308a76288",
            "7d522b98ef91458dacf3836e273f43ba",
            "75115936b6314b18bc5d4b880adf2431",
            "ae74a6207c054892863de976345dedb6",
            "9ed5631fd4704d04a9f1bba50ea213e5",
            "34ad22c1bfee45aa9f0ec989a0b671d2",
            "7eb3c6cde2a444649dab15eb8738e770",
            "881ce383b2034db1bfb642ae214501f1",
            "a17410b871f54fbab8ee00a9a96f532a",
            "d9abd392d98c4303895e2dfa215cdc5d",
            "ab3d74aebbd34849bd7cbf315623e3e9",
            "61c5e5ea65c34949a08fa207ff84b6e1",
            "7c49e07ca53f45f59dfc77478a8673cb",
            "d5f2745c69a74fcfb504c6cf3c7834ab",
            "27c1abbc75b446a8ac8853ae3015b677",
            "d0665c2151f54451b8a42372e08fa693",
            "65a62cb64ae8495894a43a769d1629c2",
            "90cea8eb2fda480cb7694cd08327c7a2",
            "7b1f3ac049b446e9b7b33089a76b7be1",
            "17d4b029a7404a1893758b4d41cb1af1",
            "35a2a1b0495c450486000b197941d7b7",
            "e08a098d26724ef283589bcc26be24df",
            "1f566808e9b848e8891c6d82b8299144",
            "2f7cc90bf3084fdeba5a0b400a0de0a5",
            "14ac573e78b04cdaa3e5d02d113c0bcb",
            "05ebf7940b5e4121beb14abd31e6c43c",
            "31c01c37ce9a40a6bcf256fede963ae4",
            "f1606d449ea74f30a5ec8868cdaddb86",
            "f9609d55332949a19b298088c462beed",
            "964de911c2174d86b7d9e0c41f23731d",
            "d2360e422996484a855de2fbe0123765",
            "26a0b27be62c4401b41935eb69bbf50a",
            "16448ff91976448182b8d9d77e4c817b",
            "be56a6274b3b40bdba1361ab7fef20ea",
            "6d2c0da1847f4af6be62e45fb1e837b3",
            "779027e617f0467881f566b43ee938a6",
            "492f1448b2a54ae3a73b894b730b95ca",
            "fea0bd438738457ab56b8d292ef90eff",
            "b18b2849e5cb4c54a63b168482e15f5b",
            "24fa83f2329242eabab54c97dc72f254",
            "4012983cb7e345738d42c8e50b2aaeb2",
            "eff17c418fe54d5aa14f9650c86a1d7c",
            "f54e57c8602f41d9975fb45e8a7bb5e6",
            "573d69626d3c4aaeaa10de96291013cd",
            "6b4057fb755e4bb1b639f3590914770e",
            "431b60fc493b4f699e3cbc541f114e21",
            "e266e21068074c6687736a85051179b6",
            "dcee26a72f554bf495275d4ae8da1660",
            "03d9ce29b9c74c248301e8c681548681",
            "07df3b6eab564baca92ae334dd307960",
            "3653923143c34a468069e700fcd2d665",
            "d3d5a48d1f12456688df070b595aef2d",
            "7f1605192a074c7d88a6f3f13d978186",
            "333fedcd448f4ed2847b6fe3cdefef33",
            "1cda39d7106a4586bbf24740d9d45ece",
            "3fb55e9a76084f7d998a389caa6c2a33",
            "f2a39b648d804c008bd49258023a921c",
            "16f90536f0a441059277075a268f03a3",
            "3e29803cc2034f5caa750bcae4b462aa",
            "09b1b2cba7384f06b87a31e89a89a879",
            "29e9c5089dfc49e2b1ee7fb6124a52ab",
            "91b30903f4a349ee88812007953b9c70",
            "d9c75ba8a49e4276b916fd16254edf2b",
            "528ec5fabacc4260b804dba7b9ede325"
          ]
        },
        "outputId": "9bb782ea-af1d-418c-e552-e25138024701"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "673a38af197d4e55834054b30e7951e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a716c640869749cb85103cf50421a19a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9abd392d98c4303895e2dfa215cdc5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35a2a1b0495c450486000b197941d7b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26a0b27be62c4401b41935eb69bbf50a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f54e57c8602f41d9975fb45e8a7bb5e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "333fedcd448f4ed2847b6fe3cdefef33"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_id = \"google/flan-t5-base\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NRLTF38FSHN",
        "outputId": "f7b4ef5b-999b-4f1f-bf4a-9a78385f192f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 1,769,472 || all params: 249,347,328 || trainable%: 0.7096414524241463\n"
          ]
        }
      ],
      "source": [
        "from peft import TaskType\n",
        "\n",
        "#model.gradient_checkpointing_enable()\n",
        "#model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "model = get_peft_model(model, config)\n",
        "\n",
        "# print number of trainable parameters\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09yr0Rc2GT3U",
        "outputId": "dbca5ded-7641-4cde-cfa9-bde4e922443d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32 249347328 1.0\n"
          ]
        }
      ],
      "source": [
        "# Verifying the datatypes.\n",
        "dtypes = {}\n",
        "for _, p in model.named_parameters():\n",
        "    dtype = p.dtype\n",
        "    if dtype not in dtypes:\n",
        "        dtypes[dtype] = 0\n",
        "    dtypes[dtype] += p.numel()\n",
        "total = 0\n",
        "for k, v in dtypes.items():\n",
        "    total += v\n",
        "for k, v in dtypes.items():\n",
        "    print(k, v, v / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e3NmQ15AGT3V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "7d8e14814a704086bb8601809ba43f10",
            "15760ab1562040a0bd1a75f2739d2af9",
            "5f1c30eb66814430b183beb33e3f3d78",
            "05c75ad5201748d6bf4f625841c97ef5",
            "2bb746f61c7242dba2361357109b2cb0",
            "7004235a5a734e2291ce438b39cfc8bb",
            "787545fc066e469eafec50ebf7b31ea4",
            "333d64909f094b1c88e84a7ae6ada70e",
            "415027eadecf4873b0e5f17073c2f11a",
            "8961bde03ad94d098a738405e01f53da",
            "336b45364085492fb99eae49ae11e3d6",
            "39722da02d8d4287b37127b81cb1f7d2",
            "b8012cfe4af84cd685f391dc88eab083",
            "4e6e4193979b47c490417120ae144dbd",
            "b082da49d4bf4547bad7285a48380c8c",
            "412b99b0cc6e421788c2f7b0cff518a8",
            "eee6d216ccdd42978f7540fd578cc7e2",
            "9b6154a8fb774c14a964614a03bc664e",
            "0ceadebf500c41119860acbc8c91336c",
            "31d96e8c627e43b4aa633dbcb5985cbb",
            "b1f8ee5803d24570843d643f8a948f88",
            "38e80ea1d2b54d6887389a1f062530bf"
          ]
        },
        "outputId": "fd0d2e9e-3f26-43a1-fb42-7b6c6ba3d210"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d8e14814a704086bb8601809ba43f10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39722da02d8d4287b37127b81cb1f7d2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "max_input_length = 512\n",
        "# change max input length of tokenizer to max_input_length\n",
        "tokenizer.model_max_length = max_input_length\n",
        "with open(\"../../submission_items/gen_dataset_NotAnAGI.json\", \"rb\") as reader:\n",
        "    dataset = build_finetuning_hf_dataset(json.load(reader), tokenizer=tokenizer, max_input_length=max_input_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_-SrItLKVDP",
        "outputId": "1f1ca67a-d9c8-4dac-887a-e23484ca3c2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10114\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 533\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMswsTqfGT3X",
        "outputId": "9d3fef38-7794-476d-898a-de0c14913d1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  304,  1731,     6,   752,    31,     7,  1431,    91,     8,  3893,\n",
              "           21,  1514,   371,  3229,    10,  1514,  3229,   377,  3274,     3,\n",
              "            2,  3357,   107,   115,   115,     2,   427,     2,   834,   476,\n",
              "            3,     2,  2152,  1027,   599,   476,    61,  3274,     3,     2,\n",
              "         3357,   107,   115,   115,     2,   427,     2,   834,   476,     3,\n",
              "            2,  2152,     3,     2,    77,    17,     3,    26,     4,     3,\n",
              "           15,     2,    18,     2,  9880,     2,   599,   476,    18,     4,\n",
              "           61,     2,   357,     2,   357,     2,  2962,    40,    17,     9,\n",
              "            2,   276,   599,     4,    61,  1514,  3229,   852,     6,   752,\n",
              "           31,     7,   240,     8, 21875,    13,  1514,   371,  3229,    28,\n",
              "         1445,    12,  1514,     2,  2962,    40,    17,     9,     2,  2292,\n",
              "            2,  3229,    10,  1514,  3229,     3,     2,   346,   122,    77,\n",
              "            2,   138,  6962,    26,     2,     3,     2,  1893, 10646,   834,\n",
              "            2,  2962,    40,    17,     9,     2,  2292,     2,   377,     3,\n",
              "          184,  2423,     3,     2,  3357,   107,   115,   115,     2,   427,\n",
              "            2,   834,   476,     3,     2,  9880,     2,    77,    17,     3,\n",
              "           26,     4,     3,     2,  9880,     2,   599,   476,    18,     4,\n",
              "           61,     2,   357,     2,   357,     2,     3,    15,     2,    18,\n",
              "            2,  9880,     2,   599,   476,    18,     4,    61,     2,   357,\n",
              "            2,   357,     2,  2962,    40,    17,     9,     2,   276,   599,\n",
              "            4,    61,     2,    77,    17,     3,    26,     4,     3,    15,\n",
              "            2,    18,     2,  9880,     2,   599,   476,    18,     4,    61,\n",
              "            2,   357,     2,   357,     2,  2962,    40,    17,     9,     2,\n",
              "          276,   599,     4,    61,     2,     3,     2,     3,   184,  2423,\n",
              "            3,     2,  3357,   107,   115,   115,     2,   427,     2,   834,\n",
              "          476,     3,     2,  9880,     2,    77,    17,     3,    26,     4,\n",
              "            3,     2, 17068,   599,     2,  9880,     2,   599,   476,    18,\n",
              "            4,    61,     2,   357,     2,   357,     2,  2962,    40,    17,\n",
              "            9,     2,    18,     2,  9880,     2,   536,     2,   357,     2,\n",
              "         3535,    61,     3,    15,     2,    18,     2,  9880,     2,   599,\n",
              "          476,    18,     4,    61,     2,   357,     2,   357,     2,  2962,\n",
              "           40,    17,     9,     2,   276,   599,     4,    61,     2,    77,\n",
              "           17,     3,    26,     4,     3,    15,     2,    18,     2,  9880,\n",
              "            2,   599,   476,    18,     4,    61,     2,   357,     2,   357,\n",
              "            2,  2962,    40,    17,     9,     2,   276,   599,     4,    61,\n",
              "            2,  1768,     3,     2,  9880,     2,   536,     2,   357,     2,\n",
              "            3,     2,     3,   184,  2423,     3,     2,  3357,   107,   115,\n",
              "          115,     2,   427,     2,   834,   476,     3,     2, 17068,  6306,\n",
              "            2,  9880,     2,    40, 13247,    41,     4,    18,   476,    61,\n",
              "            2,   357,     2,    52, 13247,     2,   357,     2,  2962,    40,\n",
              "           17,     9,     2,     3,    18,     3,     2,  9880,     2,   536,\n",
              "            2,   357,     2,  3535,   908,  1768,     3,     2,  9880,     2,\n",
              "          536,     2,   357,     2,     3,     2,     3,   184,  2423,     3,\n",
              "            2,  3357,   107,   115,   115,     2,   427,     2,   834,   476,\n",
              "            3,     2, 17068,  6306,     2,  9880,     2,    40, 13247,     3,\n",
              "            4,     2,   357,     2,    52, 13247,     3,    18,   204,     2,\n",
              "           40, 13247,     3,     4,   476,     2,    52, 13247,  1768,     3,\n",
              "            2,    40, 13247,     3,   476,     2,   357,     2,    52, 13247,\n",
              "            2,   357,     2,  2962,    40,    17,     9,     2,     3,    18,\n",
              "            3,     2,  9880,     2,   536,     2,   357,     2,  3535,   908,\n",
              "         1768,     3,     2,  9880,     2,   536,     2,   357,     2,     3,\n",
              "            2,     1])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset[\"train\"][1][\"labels\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzHvGaTuUF04",
        "outputId": "f18d4504-540d-4d20-b906-0ae755fff7bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(dataset[\"train\"][1][\"labels\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JmWC8XbGT3X"
      },
      "source": [
        "# Before training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-W7er51GT3Y",
        "outputId": "7bf34398-040a-4740-fe9e-7226a8ae2023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULT:  0\n",
            "The redshift of the galaxies is about 5 and the wavelength range is 6000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 6000 to 7000 Angström. The wavelength range of the infrared filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 6000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström. The wavelength range of the ultraviolet filter is about 7000 to 7000 Angström\n",
            "INPUT:  0\n",
            "Question: We look for signs of the stellar formation in very old galaxies with the redshift of about 5. So one wants to observe the H alpha emission line in the gas clouds made of ionised hydrogen. The R filter (covering the wavelength range from 6000 to 7000 Angström) seems to be the right filter to use. Unfortunately, there is nothing in the images. Why? (A) Because of the cosmological shift towards smaller wavelengths at high redshift, one has to observe the H alpha line in an ultraviolet filter. (B) Because of the shift towards longer wavelengths at high redshift, one has to observe the H alpha line in an infrared filter. (C) Probably the R filter is dirty, one has to clean it. (D) The galaxies at very high redshift are not bright enough to be observed. Answer: Let’s think step by step: Answer: \n",
            "LABEL:  0\n",
            "At high redshift, there is a cosmological shift towards longer wavelengths, meaning that the H alpha emission line will be shifted towards longer wavelengths. Therefore, (A) is not correct. It is also not likely that the filter is dirty, so (C) can be ruled out. The correct answer is (B), because the shift towards longer wavelengths means that the H alpha line will be shifted towards the infrared part of the spectrum, and therefore one needs an infrared filter to observe it. Finally, (D) is not necessarily correct, as there are ways to observe faint galaxies even at high redshifts, such as using longer exposure times or larger telescopes.\n",
            "--------------------------------------------------------\n",
            "RESULT:  1\n",
            "T_A = T_A(M) = AM-MA$,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
            "INPUT:  1\n",
            "Question: Peut-tu mieux expliquer ton raisonnement? Answer: Bien sûr! Tout d'abord, rappelons que l'application linéaire $T_A:Vto V$ est définie par $T_A(M)=AM-MA$, où $A$ est la matrice donnée dans l'énoncé et $V$ est le sous-espace vectoriel de $M_2times 2(mathbbR)$ constitué des matrices symétriques. Ensuite, on nous demande de calculer l'image d'une matrice symétrique générique de $V$ sous l'action de $T_A$. Cette matrice est de la forme $beginpmatrix a & b  b & c endpmatrix$, où $a,b,c$ sont des réels quelconques. Ainsi, on calcule: $$ beginaligned T_Aleft( beginpmatrix a & b  b & c endpmatrixright) &= A beginpmatrix a & b  b & c endpmatrix - beginpmatrix a & b  b & c endpmatrix A  &= beginpmatrix -2 & 4 & 0  0 & 3 & 0  1 & -2 & 1 endpmatrix beginpmatrix a & b  b & c endpmatrix - beginpmatrix a & b  b & c endpmatrix beg\n",
            "LABEL:  1\n",
            "Bien sûr, voici la réponse sous forme de LaTeX: La réponse correcte est: $$T_Aleft( beginpmatrix a & b  b & c endpmatrixright) = beginpmatrix -2a+4b & a-2b+c  a-2b+c & 3c endpmatrix.$$\n",
            "--------------------------------------------------------\n",
            "RESULT:  2\n",
            "(f:mathbbRtomathbbR) a fonction deux fois dérivable sur (mathbbR) et (f',f'':mathbbRtomathbbR) s fonctions de première et deuxième. Alors 1) (f) est continue sur (mathbbR) 2) (f') est continue sur (mathbbR) 3) (f'') est continue sur (mathbbR) 4) pour tout (x_0inmathbbR) (displaystylelim_xto x_0f'(x)) existe 5) pour tout (x_0inmathbbR) (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe\n",
            "INPUT:  2\n",
            "Question: Soit (f:mathbbRtomathbbR) une fonction deux fois dérivable sur (mathbbR) et (f',f'':mathbbRtomathbbR) ses fonctions dérivées première et deuxième. Alors 1) (f) est continue sur (mathbbR) 2) (f') est continue sur (mathbbR) 3) (f'') est continue sur (mathbbR) 4) pour tout (x_0inmathbbR) (displaystylelim_xto x_0f'(x)) existe 5) pour tout (x_0inmathbbR) (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe Answer: \n",
            "LABEL:  2\n",
            "Tout d'abord, nous savons que la dérivabilité de (f) implique sa continuité. Donc, la proposition 1 est vraie car (f) est deux fois dérivable, donc elle est aussi dérivable et donc continue. Ensuite, la proposition 2 est vraie car si (f) est deux fois dérivable, alors sa dérivée première (f') est dérivable. Et nous savons que la dérivabilité implique la continuité. La proposition 3 n'est pas nécessairement vraie. Le fait que (f'') existe ne garantit pas sa continuité. Par exemple, la fonction (f(x)=|x|) est deux fois dérivable sur (mathbbR), mais sa dérivée seconde n'est pas continue en (x=0). La proposition 4 est vraie car si (f') est dérivable en (x_0), alors elle est continue en (x_0). Enfin, la proposition 5 est vraie car si (f'') existe en (x_0), alors la limite (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe et est égale à (f''(x_0)). Cela correspond à la définition de la dérivée seconde de (f) en (x_0).\n",
            "--------------------------------------------------------\n",
            "RESULT:  3\n",
            "[mathjaxinline][mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1=[/mathjaxinline]\n",
            "INPUT:  3\n",
            "Question: In the case where [mathjaxinline]alpha=1, beta=0.1, [/mathjaxinline][mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1=[/mathjaxinline] Answer: \n",
            "LABEL:  3\n",
            "Assuming that [mathjaxinline]G(z)[/mathjaxinline] is the generating function for the sequence [mathjaxinline]n_k[/mathjaxinline], where [mathjaxinline]n_k[/mathjaxinline] denotes the number of occurrences of some event in the k-th trial, we have: [mathjaxinline]G(z) = sum_k=0infty n_k zk[/mathjaxinline] Given that [mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1[/mathjaxinline], we can differentiate [mathjaxinline]G(z)[/mathjaxinline] with respect to [mathjaxinline]z[/mathjaxinline] and then set [mathjaxinline]z=1[/mathjaxinline] to obtain: [mathjaxinline]langle nrangle = left.fracpartial Gpartial zright|_z=1 = sum_k=1infty k n_k[/mathjaxinline] Now, using the fact that [mathjaxinline]alpha=1[/mathjaxinline] and [mathjaxinline]beta=0.1[/mathjaxinline], we can write: [mathjaxinline]n_k = frac(k-1)!(1-alpha-beta)k!alphakbeta1-1 = frac110kalphak[/mathjaxinline] Substituting this expression for [mathjaxinline]n_k[/mathjaxinline] into the equation for [mathjaxinline]langle nrangle[/mathjaxinline], we get: [\n",
            "--------------------------------------------------------\n",
            "RESULT:  4\n",
            "hyperparameters\n",
            "INPUT:  4\n",
            "Question: Classify the following quantity as parameters (P) or hyperparameters (H) of a learning algorithm: The cluster assignments in a k-means algorithm. Answer: \n",
            "LABEL:  4\n",
            "In a k-means algorithm, the cluster assignments are parameters (P) rather than hyperparameters (H). Here's why: - Parameters are variables that are learned during the training process. In the case of k-means, the cluster assignments (i.e., which data points belong to which cluster) are determined during the training process and are updated iteratively until convergence. Therefore, they are considered parameters of the algorithm. - Hyperparameters, on the other hand, are values that are set before the training process begins and are not learned during training. Examples of hyperparameters in k-means include the number of clusters (k), the initialization method, and the convergence criteria. These hyperparameters are set before the training process begins and are not updated during training. So, in summary, the cluster assignments in a k-means algorithm are parameters (P) of the algorithm rather than hyperparameters (H).\n",
            "--------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def generate_example(model, tokenizer, dataset, num_examples=5):\n",
        "    for i in range(num_examples):\n",
        "        example_input = dataset[\"test\"][i][\"input_ids\"].to(\"cuda\")\n",
        "        example_label = dataset[\"test\"][i][\"labels\"].to(\"cuda\")\n",
        "\n",
        "        output = model.generate(\n",
        "            input_ids=example_input.unsqueeze(0),\n",
        "            max_new_tokens=1000,\n",
        "            temperature=0.9,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=1,\n",
        "            #repetition_penalty=100.0\n",
        "\n",
        "        )\n",
        "\n",
        "        print(\"RESULT: \", i)\n",
        "        print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "        # decode input and label\n",
        "        print(\"INPUT: \", i)\n",
        "        print(tokenizer.decode(example_input, skip_special_tokens=True))\n",
        "        print(\"LABEL: \", i)\n",
        "        print(tokenizer.decode(example_label, skip_special_tokens=True))\n",
        "        print(\"--------------------------------------------------------\")\n",
        "\n",
        "generate_example(model, tokenizer, dataset, num_examples=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6dT-Jz9FSHO"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "training_args = TrainingArguments(\n",
        "    #auto_find_batch_size=True,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=4,\n",
        "    learning_rate=1e-3,\n",
        "    #learning_rate=5e-5,\n",
        "    fp16=False,\n",
        "    save_total_limit=4,\n",
        "    logging_steps=5,\n",
        "    eval_steps=100,\n",
        "    output_dir=\"./outputs\",\n",
        "    save_strategy='epoch',\n",
        "    #optim=\"paged_adamw_8bit\",\n",
        "    lr_scheduler_type = 'cosine',\n",
        "    warmup_ratio = 0.1,\n",
        ")\n",
        "class ConversationTrainer(Trainer):    \n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        assert return_outputs == False, \"we did not implement return_outputs=True in RewardTrainer.compute_loss\"\n",
        "        \n",
        "        #print(\"inputs: \", inputs)\n",
        "        input_ids = inputs[\"input_ids\"]\n",
        "        labels = inputs[\"labels\"]\n",
        "        #print(\"labels: \", labels)\n",
        "        print(\"len inputs: \", input_ids.shape)\n",
        "        print(\"len labels: \", labels.shape)\n",
        "        loss, outputs = Trainer.compute_loss(self, model, inputs, return_outputs=True)\n",
        "        print(\"loss: \", loss)\n",
        "        print(\"outputs: \", outputs)\n",
        "        wefwefw\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "# we want to ignore tokenizer pad token in the loss\n",
        "label_pad_token_id = -100\n",
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    padding=\"max_length\",\n",
        "    label_pad_token_id=label_pad_token_id,\n",
        "    pad_to_multiple_of=8\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    args=training_args,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Ub9IfSCGT3Z",
        "outputId": "a09aec5d-dcb8-49e4-971f-284aa1d62174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2528' max='2528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2528/2528 2:32:50, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.146700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.309300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>2.138300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>2.294100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>2.153200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.331300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>2.098300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>2.157900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>2.143300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.151900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>2.115500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>2.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>2.096900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>2.104300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>2.061300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>2.046500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>2.092600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>2.091200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>2.102300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.030800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>2.083100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.958200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>2.050800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.967400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>2.013800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.982100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.989300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>2.054000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>2.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.947400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>1.985400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>2.004700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>1.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.968500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>1.939200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>2.049500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>1.988600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>2.059300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>1.880800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.918800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>1.908000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.979600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>1.934300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.931700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.761600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>1.832600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.789500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>1.954100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.917100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>1.972600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>1.904700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>1.947400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.846800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>1.871100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.866500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>1.807400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.936700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>1.834400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.788300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>1.833600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>1.879200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>1.783100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.852800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.824800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>1.802400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>1.964200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.895600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>1.928500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.934400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>1.821700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.844100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>1.756800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.953200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>1.888800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.812700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>1.854400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.906100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>1.949800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.833300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>1.900300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>1.797300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>1.835800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>1.896100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>1.846800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.874600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>1.864800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.942600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>1.838100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.819700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>1.815000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>1.755000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>1.753500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>1.909300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>1.723600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>1.902400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>1.835000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>1.974100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>1.893700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.754500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>505</td>\n",
              "      <td>1.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>1.854200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>515</td>\n",
              "      <td>1.906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>1.743700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>1.855700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>1.820800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>535</td>\n",
              "      <td>1.777800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>1.818400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>545</td>\n",
              "      <td>1.825300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>1.957900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>555</td>\n",
              "      <td>1.870100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>1.721600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>565</td>\n",
              "      <td>1.715600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>1.843100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>1.792400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>1.793400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>585</td>\n",
              "      <td>1.778700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>1.808600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>595</td>\n",
              "      <td>1.779600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.866300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>605</td>\n",
              "      <td>1.825900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>1.773200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>615</td>\n",
              "      <td>1.728200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>1.880400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>1.820300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>1.673600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>635</td>\n",
              "      <td>1.721500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>1.816500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>645</td>\n",
              "      <td>1.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>1.787200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>655</td>\n",
              "      <td>1.922300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>1.790500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>665</td>\n",
              "      <td>1.847600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>670</td>\n",
              "      <td>1.721600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>1.781900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>680</td>\n",
              "      <td>1.779300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>685</td>\n",
              "      <td>1.931000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>690</td>\n",
              "      <td>1.825800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>695</td>\n",
              "      <td>1.822500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>1.789400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>705</td>\n",
              "      <td>1.702400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>710</td>\n",
              "      <td>1.731100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>715</td>\n",
              "      <td>1.838600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>1.709600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>1.811300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>730</td>\n",
              "      <td>1.810200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>735</td>\n",
              "      <td>1.794200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>740</td>\n",
              "      <td>1.721500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>745</td>\n",
              "      <td>1.833800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>1.849900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>755</td>\n",
              "      <td>1.587700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>760</td>\n",
              "      <td>1.750300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>765</td>\n",
              "      <td>1.780500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>770</td>\n",
              "      <td>1.823500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>1.724400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>780</td>\n",
              "      <td>1.615000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>785</td>\n",
              "      <td>1.774300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>790</td>\n",
              "      <td>1.770100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>795</td>\n",
              "      <td>1.875900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>1.865900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>805</td>\n",
              "      <td>1.736300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>810</td>\n",
              "      <td>1.705800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>815</td>\n",
              "      <td>1.762100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>820</td>\n",
              "      <td>1.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>1.839000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>830</td>\n",
              "      <td>1.643500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>835</td>\n",
              "      <td>1.759800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>1.805800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>845</td>\n",
              "      <td>1.764800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>1.796200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>855</td>\n",
              "      <td>1.822700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>860</td>\n",
              "      <td>1.727500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>865</td>\n",
              "      <td>1.723600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>870</td>\n",
              "      <td>1.742500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>1.737800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>880</td>\n",
              "      <td>1.763400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>885</td>\n",
              "      <td>1.693700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>890</td>\n",
              "      <td>1.759000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>895</td>\n",
              "      <td>1.761800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>1.809000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>905</td>\n",
              "      <td>1.956400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>910</td>\n",
              "      <td>1.699100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>915</td>\n",
              "      <td>1.750800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>920</td>\n",
              "      <td>1.787600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>1.704900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>930</td>\n",
              "      <td>1.781900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>935</td>\n",
              "      <td>1.701400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>940</td>\n",
              "      <td>1.680700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>945</td>\n",
              "      <td>1.614200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>1.720600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>955</td>\n",
              "      <td>1.797600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>1.723900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>965</td>\n",
              "      <td>1.836600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>970</td>\n",
              "      <td>1.694000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>1.693900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>980</td>\n",
              "      <td>1.903100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>985</td>\n",
              "      <td>1.658400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>990</td>\n",
              "      <td>1.857400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>995</td>\n",
              "      <td>1.827500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.850200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1005</td>\n",
              "      <td>1.720900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1010</td>\n",
              "      <td>1.664900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1015</td>\n",
              "      <td>1.685900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1020</td>\n",
              "      <td>1.745700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>1.684800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1030</td>\n",
              "      <td>1.685700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1035</td>\n",
              "      <td>1.674800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1040</td>\n",
              "      <td>1.664200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1045</td>\n",
              "      <td>1.648500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>1.749700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1055</td>\n",
              "      <td>1.667900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1060</td>\n",
              "      <td>1.729900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1065</td>\n",
              "      <td>1.836000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1070</td>\n",
              "      <td>1.651400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>1.837600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>1.824700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1085</td>\n",
              "      <td>1.858300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1090</td>\n",
              "      <td>1.753900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1095</td>\n",
              "      <td>1.787400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>1.680600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1105</td>\n",
              "      <td>1.786200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1110</td>\n",
              "      <td>1.662800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1115</td>\n",
              "      <td>1.738700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1120</td>\n",
              "      <td>1.696700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>1.706300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1130</td>\n",
              "      <td>1.594700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1135</td>\n",
              "      <td>1.710000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1140</td>\n",
              "      <td>1.769700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1145</td>\n",
              "      <td>1.760800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>1.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1155</td>\n",
              "      <td>1.790700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1160</td>\n",
              "      <td>1.707700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1165</td>\n",
              "      <td>1.717100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1170</td>\n",
              "      <td>1.783400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>1.657600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1180</td>\n",
              "      <td>1.715500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1185</td>\n",
              "      <td>1.685600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1190</td>\n",
              "      <td>1.745000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1195</td>\n",
              "      <td>1.870200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>1.825800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1205</td>\n",
              "      <td>1.659700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1210</td>\n",
              "      <td>1.745500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1215</td>\n",
              "      <td>1.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1220</td>\n",
              "      <td>1.771400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>1.781300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1230</td>\n",
              "      <td>1.822600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1235</td>\n",
              "      <td>1.620700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1240</td>\n",
              "      <td>1.616900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1245</td>\n",
              "      <td>1.719600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>1.713100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1255</td>\n",
              "      <td>1.593100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1260</td>\n",
              "      <td>1.711000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1265</td>\n",
              "      <td>1.642000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1270</td>\n",
              "      <td>1.783200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>1.674800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1280</td>\n",
              "      <td>1.677300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1285</td>\n",
              "      <td>1.794100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1290</td>\n",
              "      <td>1.696200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1295</td>\n",
              "      <td>1.708500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>1.659400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1305</td>\n",
              "      <td>1.740900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1310</td>\n",
              "      <td>1.710400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1315</td>\n",
              "      <td>1.642200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>1.640700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>1.674800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1330</td>\n",
              "      <td>1.723200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1335</td>\n",
              "      <td>1.629900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1340</td>\n",
              "      <td>1.660700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1345</td>\n",
              "      <td>1.705300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>1.524600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1355</td>\n",
              "      <td>1.632400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1360</td>\n",
              "      <td>1.676700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1365</td>\n",
              "      <td>1.755900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1370</td>\n",
              "      <td>1.716200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>1.630400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1380</td>\n",
              "      <td>1.707500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1385</td>\n",
              "      <td>1.822100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1390</td>\n",
              "      <td>1.644100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1395</td>\n",
              "      <td>1.674800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>1.720300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1405</td>\n",
              "      <td>1.780200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1410</td>\n",
              "      <td>1.691400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1415</td>\n",
              "      <td>1.709500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1420</td>\n",
              "      <td>1.633900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>1.607400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1430</td>\n",
              "      <td>1.711300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1435</td>\n",
              "      <td>1.665400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>1.671200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1445</td>\n",
              "      <td>1.704400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>1.663500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1455</td>\n",
              "      <td>1.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1460</td>\n",
              "      <td>1.653400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1465</td>\n",
              "      <td>1.638100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1470</td>\n",
              "      <td>1.828200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>1.673500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1480</td>\n",
              "      <td>1.641800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1485</td>\n",
              "      <td>1.711600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1490</td>\n",
              "      <td>1.797700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1495</td>\n",
              "      <td>1.753200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.726500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1505</td>\n",
              "      <td>1.734200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1510</td>\n",
              "      <td>1.626600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1515</td>\n",
              "      <td>1.599800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1520</td>\n",
              "      <td>1.688100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>1.691200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1530</td>\n",
              "      <td>1.564600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1535</td>\n",
              "      <td>1.755000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1540</td>\n",
              "      <td>1.565500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1545</td>\n",
              "      <td>1.641500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>1.623600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1555</td>\n",
              "      <td>1.675300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>1.570200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1565</td>\n",
              "      <td>1.686600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1570</td>\n",
              "      <td>1.682400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>1.700800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1580</td>\n",
              "      <td>1.714800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1585</td>\n",
              "      <td>1.625700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1590</td>\n",
              "      <td>1.630300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1595</td>\n",
              "      <td>1.636500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>1.725300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1605</td>\n",
              "      <td>1.730200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1610</td>\n",
              "      <td>1.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1615</td>\n",
              "      <td>1.598000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1620</td>\n",
              "      <td>1.739400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>1.644100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1630</td>\n",
              "      <td>1.797500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1635</td>\n",
              "      <td>1.600600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1640</td>\n",
              "      <td>1.692100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1645</td>\n",
              "      <td>1.759200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>1.571300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1655</td>\n",
              "      <td>1.580700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1660</td>\n",
              "      <td>1.706100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1665</td>\n",
              "      <td>1.687000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1670</td>\n",
              "      <td>1.805800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>1.780800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>1.632300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1685</td>\n",
              "      <td>1.599200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1690</td>\n",
              "      <td>1.686200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1695</td>\n",
              "      <td>1.675200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>1.720900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1705</td>\n",
              "      <td>1.623500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1710</td>\n",
              "      <td>1.658000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1715</td>\n",
              "      <td>1.872800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1720</td>\n",
              "      <td>1.706100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>1.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1730</td>\n",
              "      <td>1.737600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1735</td>\n",
              "      <td>1.692600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1740</td>\n",
              "      <td>1.686800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1745</td>\n",
              "      <td>1.766500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>1.619900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1755</td>\n",
              "      <td>1.601400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1760</td>\n",
              "      <td>1.762800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1765</td>\n",
              "      <td>1.632500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1770</td>\n",
              "      <td>1.631500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>1.719200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1780</td>\n",
              "      <td>1.629200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1785</td>\n",
              "      <td>1.616900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1790</td>\n",
              "      <td>1.622100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1795</td>\n",
              "      <td>1.653000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>1.764600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1805</td>\n",
              "      <td>1.734700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1810</td>\n",
              "      <td>1.668300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1815</td>\n",
              "      <td>1.753400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1820</td>\n",
              "      <td>1.648700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>1.688500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1830</td>\n",
              "      <td>1.574000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1835</td>\n",
              "      <td>1.628300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1840</td>\n",
              "      <td>1.619300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1845</td>\n",
              "      <td>1.653000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>1.543100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1855</td>\n",
              "      <td>1.654700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1860</td>\n",
              "      <td>1.673800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1865</td>\n",
              "      <td>1.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1870</td>\n",
              "      <td>1.625300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>1.684300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1880</td>\n",
              "      <td>1.716300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1885</td>\n",
              "      <td>1.708500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1890</td>\n",
              "      <td>1.719100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1895</td>\n",
              "      <td>1.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>1.518700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1905</td>\n",
              "      <td>1.524100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1910</td>\n",
              "      <td>1.574200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1915</td>\n",
              "      <td>1.743100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>1.783800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>1.648600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1930</td>\n",
              "      <td>1.679300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1935</td>\n",
              "      <td>1.627900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1940</td>\n",
              "      <td>1.575500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1945</td>\n",
              "      <td>1.695900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>1.778200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1955</td>\n",
              "      <td>1.653900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1960</td>\n",
              "      <td>1.676600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1965</td>\n",
              "      <td>1.694400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1970</td>\n",
              "      <td>1.636200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>1.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1980</td>\n",
              "      <td>1.647800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1985</td>\n",
              "      <td>1.630900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1990</td>\n",
              "      <td>1.604700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1995</td>\n",
              "      <td>1.695300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.764900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2005</td>\n",
              "      <td>1.708500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2010</td>\n",
              "      <td>1.733100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2015</td>\n",
              "      <td>1.575800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2020</td>\n",
              "      <td>1.705300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>1.612100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2030</td>\n",
              "      <td>1.738700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2035</td>\n",
              "      <td>1.707600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>1.614100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2045</td>\n",
              "      <td>1.651000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>1.698500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2055</td>\n",
              "      <td>1.599200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2060</td>\n",
              "      <td>1.508700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2065</td>\n",
              "      <td>1.647300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2070</td>\n",
              "      <td>1.643600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>1.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2080</td>\n",
              "      <td>1.603400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2085</td>\n",
              "      <td>1.681300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2090</td>\n",
              "      <td>1.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2095</td>\n",
              "      <td>1.638800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>1.659000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2105</td>\n",
              "      <td>1.645700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2110</td>\n",
              "      <td>1.713300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2115</td>\n",
              "      <td>1.459100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2120</td>\n",
              "      <td>1.647100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>1.676600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2130</td>\n",
              "      <td>1.571600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2135</td>\n",
              "      <td>1.679000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2140</td>\n",
              "      <td>1.626000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2145</td>\n",
              "      <td>1.666500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>1.667700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2155</td>\n",
              "      <td>1.637600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>1.619500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2165</td>\n",
              "      <td>1.762000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2170</td>\n",
              "      <td>1.663000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>1.652200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2180</td>\n",
              "      <td>1.609800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2185</td>\n",
              "      <td>1.596100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2190</td>\n",
              "      <td>1.690300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2195</td>\n",
              "      <td>1.850600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>1.610700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2205</td>\n",
              "      <td>1.549000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2210</td>\n",
              "      <td>1.713900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2215</td>\n",
              "      <td>1.669100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2220</td>\n",
              "      <td>1.707200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>1.686100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2230</td>\n",
              "      <td>1.633400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2235</td>\n",
              "      <td>1.784600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2240</td>\n",
              "      <td>1.689400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2245</td>\n",
              "      <td>1.641600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>1.759300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2255</td>\n",
              "      <td>1.628300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2260</td>\n",
              "      <td>1.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2265</td>\n",
              "      <td>1.724500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2270</td>\n",
              "      <td>1.587200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>1.664300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>1.728300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2285</td>\n",
              "      <td>1.623500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2290</td>\n",
              "      <td>1.618200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2295</td>\n",
              "      <td>1.711900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>1.727900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2305</td>\n",
              "      <td>1.674100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2310</td>\n",
              "      <td>1.690800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2315</td>\n",
              "      <td>1.618800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2320</td>\n",
              "      <td>1.623400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>1.630700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2330</td>\n",
              "      <td>1.644200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2335</td>\n",
              "      <td>1.530700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2340</td>\n",
              "      <td>1.572300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2345</td>\n",
              "      <td>1.608500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>1.704600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2355</td>\n",
              "      <td>1.718200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2360</td>\n",
              "      <td>1.677200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2365</td>\n",
              "      <td>1.649900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2370</td>\n",
              "      <td>1.756900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>1.686000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2380</td>\n",
              "      <td>1.645500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2385</td>\n",
              "      <td>1.706700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2390</td>\n",
              "      <td>1.620600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2395</td>\n",
              "      <td>1.647600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>1.601700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2405</td>\n",
              "      <td>1.669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2410</td>\n",
              "      <td>1.647900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2415</td>\n",
              "      <td>1.671000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2420</td>\n",
              "      <td>1.603500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>1.726600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2430</td>\n",
              "      <td>1.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2435</td>\n",
              "      <td>1.623500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2440</td>\n",
              "      <td>1.589500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2445</td>\n",
              "      <td>1.614000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>1.616200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2455</td>\n",
              "      <td>1.722100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2460</td>\n",
              "      <td>1.713500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2465</td>\n",
              "      <td>1.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2470</td>\n",
              "      <td>1.555800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>1.623700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2480</td>\n",
              "      <td>1.603100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2485</td>\n",
              "      <td>1.626900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2490</td>\n",
              "      <td>1.584700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2495</td>\n",
              "      <td>1.714600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.653000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2505</td>\n",
              "      <td>1.587400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2510</td>\n",
              "      <td>1.676700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2515</td>\n",
              "      <td>1.665700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2520</td>\n",
              "      <td>1.643500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>1.623600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2528, training_loss=1.7502318441490583, metrics={'train_runtime': 9173.8973, 'train_samples_per_second': 4.41, 'train_steps_per_second': 0.276, 'total_flos': 2.7912792198610944e+16, 'train_loss': 1.7502318441490583, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint 1"
      ],
      "metadata": {
        "id": "IpD2e4cl7xvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "peft_model_id = \"../../../outputs/checkpoint-632\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
        "model1 = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model1.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7seWdk1m8z8E",
        "outputId": "c9081343-e7a9-47bb-93ab-d189392ed6cf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTUWwKyXAxc6",
        "outputId": "5351af98-6ba0-40c4-b8ee-7f09f7afe68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULT:  0\n",
            "The correct answer is (A) Because of the cosmological shift towards smaller wavelengths at high redshift, one has to observe the H alpha emission line in an ultraviolet filter. This means that there are no visible signs of stellar formation in very old galaxie with the redshift of about 5. Therefore, we need to use the R filter covering the wavelength range from 6000–7000 Angström.\n",
            "INPUT:  0\n",
            "Question: We look for signs of the stellar formation in very old galaxies with the redshift of about 5. So one wants to observe the H alpha emission line in the gas clouds made of ionised hydrogen. The R filter (covering the wavelength range from 6000 to 7000 Angström) seems to be the right filter to use. Unfortunately, there is nothing in the images. Why? (A) Because of the cosmological shift towards smaller wavelengths at high redshift, one has to observe the H alpha line in an ultraviolet filter. (B) Because of the shift towards longer wavelengths at high redshift, one has to observe the H alpha line in an infrared filter. (C) Probably the R filter is dirty, one has to clean it. (D) The galaxies at very high redshift are not bright enough to be observed. Answer: Let’s think step by step: Answer: \n",
            "LABEL:  0\n",
            "At high redshift, there is a cosmological shift towards longer wavelengths, meaning that the H alpha emission line will be shifted towards longer wavelengths. Therefore, (A) is not correct. It is also not likely that the filter is dirty, so (C) can be ruled out. The correct answer is (B), because the shift towards longer wavelengths means that the H alpha line will be shifted towards the infrared part of the spectrum, and therefore one needs an infrared filter to observe it. Finally, (D) is not necessarily correct, as there are ways to observe faint galaxies even at high redshifts, such as using longer exposure times or larger telescopes.\n",
            "--------------------------------------------------------\n",
            "RESULT:  1\n",
            "Bien sûr! Tout d'abord, rappelons que $T_A:Vto V$ est définie par $T_A(M)=AM-MA$. En effet, la fonction de calculer le système des valeurs du produit pour les deux variables sont donc déterminées dans un autre cas suivant l'application Linéaire T_A (m). Pour cela, on doit utiliser une méthode donnée comme suit: La formule \"a\" = A + B = C$ qui permet de déterminer si $A$ soit inégale au sein de ce processus ou non seulement sur le modèle M/B. On peut également vérifier qu'il existe trois dimensions permettant de trouver une solution différentielle entre ces two conditions; alors nous pouvions maintenant montrer que $C$ représente une dimension distinctielle plus large que celle dit après avoir été trouvée.\n",
            "INPUT:  1\n",
            "Question: Peut-tu mieux expliquer ton raisonnement? Answer: Bien sûr! Tout d'abord, rappelons que l'application linéaire $T_A:Vto V$ est définie par $T_A(M)=AM-MA$, où $A$ est la matrice donnée dans l'énoncé et $V$ est le sous-espace vectoriel de $M_2times 2(mathbbR)$ constitué des matrices symétriques. Ensuite, on nous demande de calculer l'image d'une matrice symétrique générique de $V$ sous l'action de $T_A$. Cette matrice est de la forme $beginpmatrix a & b  b & c endpmatrix$, où $a,b,c$ sont des réels quelconques. Ainsi, on calcule: $$ beginaligned T_Aleft( beginpmatrix a & b  b & c endpmatrixright) &= A beginpmatrix a & b  b & c endpmatrix - beginpmatrix a & b  b & c endpmatrix A  &= beginpmatrix -2 & 4 & 0  0 & 3 & 0  1 & -2 & 1 endpmatrix beginpmatrix a & b  b & c endpmatrix - beginpmatrix a & b  b & c endpmatrix beg\n",
            "LABEL:  1\n",
            "Bien sûr, voici la réponse sous forme de LaTeX: La réponse correcte est: $$T_Aleft( beginpmatrix a & b  b & c endpmatrixright) = beginpmatrix -2a+4b & a-2b+c  a-2b+c & 3c endpmatrix.$$\n",
            "--------------------------------------------------------\n",
            "RESULT:  2\n",
            "Pour déterminer si (f',f'':mathbbRtomathbm$ est continue sur (mathbubbleR), nous devons utiliser la formule suivante pour calculer les deux fonctions dérivées première et second. On peut donc trouver le résultat des trois lignes dans une colonne donné par un coefficient supérieur à celui du point inférieur qui existe au niveau élevé ou plus haut que celle entre ces two limites (c'est-à-dire) avec respect aux valeurs propres). En effet, on obtient $F_0=1+2x_-1 = 1 + 2x_-2 = 3x_-3 = 4x_-4x_-5x_-6x_-7yx_-8x_-9x_-10x_-11x_-13x_-12x_-14x_-15x_-16x_-17x_-18x_-21x_-22x_-24x_-25x_-60x_-21x_-23x_0x_0x_0x_0-27x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0\n",
            "INPUT:  2\n",
            "Question: Soit (f:mathbbRtomathbbR) une fonction deux fois dérivable sur (mathbbR) et (f',f'':mathbbRtomathbbR) ses fonctions dérivées première et deuxième. Alors 1) (f) est continue sur (mathbbR) 2) (f') est continue sur (mathbbR) 3) (f'') est continue sur (mathbbR) 4) pour tout (x_0inmathbbR) (displaystylelim_xto x_0f'(x)) existe 5) pour tout (x_0inmathbbR) (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe Answer: \n",
            "LABEL:  2\n",
            "Tout d'abord, nous savons que la dérivabilité de (f) implique sa continuité. Donc, la proposition 1 est vraie car (f) est deux fois dérivable, donc elle est aussi dérivable et donc continue. Ensuite, la proposition 2 est vraie car si (f) est deux fois dérivable, alors sa dérivée première (f') est dérivable. Et nous savons que la dérivabilité implique la continuité. La proposition 3 n'est pas nécessairement vraie. Le fait que (f'') existe ne garantit pas sa continuité. Par exemple, la fonction (f(x)=|x|) est deux fois dérivable sur (mathbbR), mais sa dérivée seconde n'est pas continue en (x=0). La proposition 4 est vraie car si (f') est dérivable en (x_0), alors elle est continue en (x_0). Enfin, la proposition 5 est vraie car si (f'') existe en (x_0), alors la limite (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe et est égale à (f''(x_0)). Cela correspond à la définition de la dérivée seconde de (f) en (x_0).\n",
            "--------------------------------------------------------\n",
            "RESULT:  3\n",
            "To solve this problem, we need to use the formula for [mathjaxinline]alpha=1, beta=0.1, [/mathjaxinline]. In this case, [mathji = 1] and [mathdi = 2], where [mathcm = 0] and [mathdi = 3] are constants. We can find that in both cases, [mathbq = -1] and [mathdi = 4] are not equal. Therefore, the correct answer is: [math_langle nrangle=left.fracpartial Gpartial zright|_z=1=[/mathjoxinline].\n",
            "INPUT:  3\n",
            "Question: In the case where [mathjaxinline]alpha=1, beta=0.1, [/mathjaxinline][mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1=[/mathjaxinline] Answer: \n",
            "LABEL:  3\n",
            "Assuming that [mathjaxinline]G(z)[/mathjaxinline] is the generating function for the sequence [mathjaxinline]n_k[/mathjaxinline], where [mathjaxinline]n_k[/mathjaxinline] denotes the number of occurrences of some event in the k-th trial, we have: [mathjaxinline]G(z) = sum_k=0infty n_k zk[/mathjaxinline] Given that [mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1[/mathjaxinline], we can differentiate [mathjaxinline]G(z)[/mathjaxinline] with respect to [mathjaxinline]z[/mathjaxinline] and then set [mathjaxinline]z=1[/mathjaxinline] to obtain: [mathjaxinline]langle nrangle = left.fracpartial Gpartial zright|_z=1 = sum_k=1infty k n_k[/mathjaxinline] Now, using the fact that [mathjaxinline]alpha=1[/mathjaxinline] and [mathjaxinline]beta=0.1[/mathjaxinline], we can write: [mathjaxinline]n_k = frac(k-1)!(1-alpha-beta)k!alphakbeta1-1 = frac110kalphak[/mathjaxinline] Substituting this expression for [mathjaxinline]n_k[/mathjaxinline] into the equation for [mathjaxinline]langle nrangle[/mathjaxinline], we get: [\n",
            "--------------------------------------------------------\n",
            "RESULT:  4\n",
            "The cluster assignments in a k-means algorithm are the number of steps that an individual can perform to achieve a goal. This is because each step requires a specific amount of time and effort, which is not necessarily necessary for the task being performed. Therefore, the correct answer is H.\n",
            "INPUT:  4\n",
            "Question: Classify the following quantity as parameters (P) or hyperparameters (H) of a learning algorithm: The cluster assignments in a k-means algorithm. Answer: \n",
            "LABEL:  4\n",
            "In a k-means algorithm, the cluster assignments are parameters (P) rather than hyperparameters (H). Here's why: - Parameters are variables that are learned during the training process. In the case of k-means, the cluster assignments (i.e., which data points belong to which cluster) are determined during the training process and are updated iteratively until convergence. Therefore, they are considered parameters of the algorithm. - Hyperparameters, on the other hand, are values that are set before the training process begins and are not learned during training. Examples of hyperparameters in k-means include the number of clusters (k), the initialization method, and the convergence criteria. These hyperparameters are set before the training process begins and are not updated during training. So, in summary, the cluster assignments in a k-means algorithm are parameters (P) of the algorithm rather than hyperparameters (H).\n",
            "--------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def generate_example(gen_model, tokenizer, dataset, num_examples=5):\n",
        "    for i in range(num_examples):\n",
        "        example_input = dataset[\"test\"][i][\"input_ids\"].to(\"cuda\")\n",
        "        example_label = dataset[\"test\"][i][\"labels\"].to(\"cuda\")\n",
        "\n",
        "        output = gen_model.generate(\n",
        "            input_ids=example_input.unsqueeze(0),\n",
        "            max_new_tokens=1000,\n",
        "            temperature=0.9,\n",
        "            top_p=0.9,\n",
        "            num_return_sequences=1,\n",
        "            repetition_penalty=100.0\n",
        "\n",
        "        )\n",
        "\n",
        "        print(\"RESULT: \", i)\n",
        "        print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "        # decode input and label\n",
        "        print(\"INPUT: \", i)\n",
        "        print(tokenizer.decode(example_input, skip_special_tokens=True))\n",
        "        print(\"LABEL: \", i)\n",
        "        print(tokenizer.decode(example_label, skip_special_tokens=True))\n",
        "        print(\"--------------------------------------------------------\")\n",
        "\n",
        "generate_example(model1, tokenizer, dataset, num_examples=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checkpoint 4"
      ],
      "metadata": {
        "id": "89JmlbXY-yl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "xa-im4bKv8Fh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f358017c-0640-4a2e-ad2d-13dd88d469fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForSeq2SeqLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): T5ForConditionalGeneration(\n",
              "      (shared): Embedding(32128, 768)\n",
              "      (encoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (decoder): T5Stack(\n",
              "        (embed_tokens): Embedding(32128, 768)\n",
              "        (block): ModuleList(\n",
              "          (0): T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (relative_attention_bias): Embedding(32, 12)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1-11): 11 x T5Block(\n",
              "            (layer): ModuleList(\n",
              "              (0): T5LayerSelfAttention(\n",
              "                (SelfAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (1): T5LayerCrossAttention(\n",
              "                (EncDecAttention): T5Attention(\n",
              "                  (q): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                  (v): Linear(\n",
              "                    in_features=768, out_features=768, bias=False\n",
              "                    (lora_dropout): ModuleDict(\n",
              "                      (default): Dropout(p=0.05, inplace=False)\n",
              "                    )\n",
              "                    (lora_A): ModuleDict(\n",
              "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
              "                    )\n",
              "                    (lora_B): ModuleDict(\n",
              "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
              "                    )\n",
              "                    (lora_embedding_A): ParameterDict()\n",
              "                    (lora_embedding_B): ParameterDict()\n",
              "                  )\n",
              "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (2): T5LayerFF(\n",
              "                (DenseReluDense): T5DenseGatedActDense(\n",
              "                  (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
              "                  (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
              "                  (dropout): Dropout(p=0.1, inplace=False)\n",
              "                  (act): NewGELUActivation()\n",
              "                )\n",
              "                (layer_norm): T5LayerNorm()\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (final_layer_norm): T5LayerNorm()\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "peft_model_id = \"../../../outputs/checkpoint-2528\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, device_map=\"auto\")\n",
        "model4 = PeftModel.from_pretrained(model, peft_model_id)\n",
        "model4.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_example(model4, tokenizer, dataset, num_examples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX3b1Dl8-6-j",
        "outputId": "b2c84b5d-d281-44f0-fe45-4d81ed8b1b53"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULT:  0\n",
            "The correct answer is (A) Because of the cosmological shift towards smaller wavelengths at high redshift, one has to observe the H alpha emission line in an ultraviolet filter. This means that there are no visible signs of stellar formation in very old galaxie with the redshift of about 5. Therefore, we need to use the R filter covering the wavelength range from 6000–7000 Angström.\n",
            "INPUT:  0\n",
            "Question: We look for signs of the stellar formation in very old galaxies with the redshift of about 5. So one wants to observe the H alpha emission line in the gas clouds made of ionised hydrogen. The R filter (covering the wavelength range from 6000 to 7000 Angström) seems to be the right filter to use. Unfortunately, there is nothing in the images. Why? (A) Because of the cosmological shift towards smaller wavelengths at high redshift, one has to observe the H alpha line in an ultraviolet filter. (B) Because of the shift towards longer wavelengths at high redshift, one has to observe the H alpha line in an infrared filter. (C) Probably the R filter is dirty, one has to clean it. (D) The galaxies at very high redshift are not bright enough to be observed. Answer: Let’s think step by step: Answer: \n",
            "LABEL:  0\n",
            "At high redshift, there is a cosmological shift towards longer wavelengths, meaning that the H alpha emission line will be shifted towards longer wavelengths. Therefore, (A) is not correct. It is also not likely that the filter is dirty, so (C) can be ruled out. The correct answer is (B), because the shift towards longer wavelengths means that the H alpha line will be shifted towards the infrared part of the spectrum, and therefore one needs an infrared filter to observe it. Finally, (D) is not necessarily correct, as there are ways to observe faint galaxies even at high redshifts, such as using longer exposure times or larger telescopes.\n",
            "--------------------------------------------------------\n",
            "RESULT:  1\n",
            "Bien sûr! Tout d'abord, rappelons que $T_A:Vto V$ est définie par $T_A(M)=AM-MA$. En effet, la fonction de calculer le système des valeurs du produit pour les deux variables sont donc déterminées dans un autre cas suivant l'application Linéaire T_A (m). Pour cela, on doit utiliser une méthode donnée comme suit: La formule \"a\" = A + B = C$ qui permet de déterminer si $A$ soit inégale au sein de ce processus ou non seulement sur le modèle M/B. On peut également vérifier qu'il existe trois dimensions permettant de trouver une solution différentielle entre ces two conditions; alors nous pouvions maintenant montrer que $C$ représente une dimension distinctielle plus large que celle dit après avoir été trouvée.\n",
            "INPUT:  1\n",
            "Question: Peut-tu mieux expliquer ton raisonnement? Answer: Bien sûr! Tout d'abord, rappelons que l'application linéaire $T_A:Vto V$ est définie par $T_A(M)=AM-MA$, où $A$ est la matrice donnée dans l'énoncé et $V$ est le sous-espace vectoriel de $M_2times 2(mathbbR)$ constitué des matrices symétriques. Ensuite, on nous demande de calculer l'image d'une matrice symétrique générique de $V$ sous l'action de $T_A$. Cette matrice est de la forme $beginpmatrix a & b  b & c endpmatrix$, où $a,b,c$ sont des réels quelconques. Ainsi, on calcule: $$ beginaligned T_Aleft( beginpmatrix a & b  b & c endpmatrixright) &= A beginpmatrix a & b  b & c endpmatrix - beginpmatrix a & b  b & c endpmatrix A  &= beginpmatrix -2 & 4 & 0  0 & 3 & 0  1 & -2 & 1 endpmatrix beginpmatrix a & b  b & c endpmatrix - beginpmatrix a & b  b & c endpmatrix beg\n",
            "LABEL:  1\n",
            "Bien sûr, voici la réponse sous forme de LaTeX: La réponse correcte est: $$T_Aleft( beginpmatrix a & b  b & c endpmatrixright) = beginpmatrix -2a+4b & a-2b+c  a-2b+c & 3c endpmatrix.$$\n",
            "--------------------------------------------------------\n",
            "RESULT:  2\n",
            "Pour déterminer si (f',f'':mathbbRtomathbm$ est continue sur (mathbubbleR), nous devons utiliser la formule suivante pour calculer les deux fonctions dérivées première et second. On peut donc trouver le résultat des trois lignes dans une colonne donné par un coefficient supérieur à celui du point inférieur qui existe au niveau élevé ou plus haut que celle entre ces two limites (c'est-à-dire) avec respect aux valeurs propres). En effet, on obtient $F_0=1+2x_-1 = 1 + 2x_-2 = 3x_-3 = 4x_-4x_-5x_-6x_-7yx_-8x_-9x_-10x_-11x_-13x_-12x_-14x_-15x_-16x_-17x_-18x_-21x_-22x_-24x_-25x_-60x_-21x_-23x_0x_0x_0x_0-27x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0x_0\n",
            "INPUT:  2\n",
            "Question: Soit (f:mathbbRtomathbbR) une fonction deux fois dérivable sur (mathbbR) et (f',f'':mathbbRtomathbbR) ses fonctions dérivées première et deuxième. Alors 1) (f) est continue sur (mathbbR) 2) (f') est continue sur (mathbbR) 3) (f'') est continue sur (mathbbR) 4) pour tout (x_0inmathbbR) (displaystylelim_xto x_0f'(x)) existe 5) pour tout (x_0inmathbbR) (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe Answer: \n",
            "LABEL:  2\n",
            "Tout d'abord, nous savons que la dérivabilité de (f) implique sa continuité. Donc, la proposition 1 est vraie car (f) est deux fois dérivable, donc elle est aussi dérivable et donc continue. Ensuite, la proposition 2 est vraie car si (f) est deux fois dérivable, alors sa dérivée première (f') est dérivable. Et nous savons que la dérivabilité implique la continuité. La proposition 3 n'est pas nécessairement vraie. Le fait que (f'') existe ne garantit pas sa continuité. Par exemple, la fonction (f(x)=|x|) est deux fois dérivable sur (mathbbR), mais sa dérivée seconde n'est pas continue en (x=0). La proposition 4 est vraie car si (f') est dérivable en (x_0), alors elle est continue en (x_0). Enfin, la proposition 5 est vraie car si (f'') existe en (x_0), alors la limite (displaystylelim_xto x_0fracf'(x)-f'(x_0)x-x_0) existe et est égale à (f''(x_0)). Cela correspond à la définition de la dérivée seconde de (f) en (x_0).\n",
            "--------------------------------------------------------\n",
            "RESULT:  3\n",
            "To solve this problem, we need to use the formula for [mathjaxinline]alpha=1, beta=0.1, [/mathjaxinline]. In this case, [mathji = 1] and [mathdi = 2], where [mathcm = 0] and [mathdi = 3] are constants. We can find that in both cases, [mathbq = -1] and [mathdi = 4] are not equal. Therefore, the correct answer is: [math_langle nrangle=left.fracpartial Gpartial zright|_z=1=[/mathjoxinline].\n",
            "INPUT:  3\n",
            "Question: In the case where [mathjaxinline]alpha=1, beta=0.1, [/mathjaxinline][mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1=[/mathjaxinline] Answer: \n",
            "LABEL:  3\n",
            "Assuming that [mathjaxinline]G(z)[/mathjaxinline] is the generating function for the sequence [mathjaxinline]n_k[/mathjaxinline], where [mathjaxinline]n_k[/mathjaxinline] denotes the number of occurrences of some event in the k-th trial, we have: [mathjaxinline]G(z) = sum_k=0infty n_k zk[/mathjaxinline] Given that [mathjaxinline]langle nrangle=left.fracpartial Gpartial zright|_z=1[/mathjaxinline], we can differentiate [mathjaxinline]G(z)[/mathjaxinline] with respect to [mathjaxinline]z[/mathjaxinline] and then set [mathjaxinline]z=1[/mathjaxinline] to obtain: [mathjaxinline]langle nrangle = left.fracpartial Gpartial zright|_z=1 = sum_k=1infty k n_k[/mathjaxinline] Now, using the fact that [mathjaxinline]alpha=1[/mathjaxinline] and [mathjaxinline]beta=0.1[/mathjaxinline], we can write: [mathjaxinline]n_k = frac(k-1)!(1-alpha-beta)k!alphakbeta1-1 = frac110kalphak[/mathjaxinline] Substituting this expression for [mathjaxinline]n_k[/mathjaxinline] into the equation for [mathjaxinline]langle nrangle[/mathjaxinline], we get: [\n",
            "--------------------------------------------------------\n",
            "RESULT:  4\n",
            "The cluster assignments in a k-means algorithm are the number of steps that an individual can perform to achieve a goal. This is because each step requires a specific amount of time and effort, which is not necessarily necessary for the task being performed. Therefore, the correct answer is H.\n",
            "INPUT:  4\n",
            "Question: Classify the following quantity as parameters (P) or hyperparameters (H) of a learning algorithm: The cluster assignments in a k-means algorithm. Answer: \n",
            "LABEL:  4\n",
            "In a k-means algorithm, the cluster assignments are parameters (P) rather than hyperparameters (H). Here's why: - Parameters are variables that are learned during the training process. In the case of k-means, the cluster assignments (i.e., which data points belong to which cluster) are determined during the training process and are updated iteratively until convergence. Therefore, they are considered parameters of the algorithm. - Hyperparameters, on the other hand, are values that are set before the training process begins and are not learned during training. Examples of hyperparameters in k-means include the number of clusters (k), the initialization method, and the convergence criteria. These hyperparameters are set before the training process begins and are not updated during training. So, in summary, the cluster assignments in a k-means algorithm are parameters (P) of the algorithm rather than hyperparameters (H).\n",
            "--------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fQRpGJq5-5ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFw3HKDIGT3Z"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "673a38af197d4e55834054b30e7951e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3559b4ddfd7d4b36be55ec7e702c5c08",
              "IPY_MODEL_2d380eda51b043ffaf301a35e1da58fe",
              "IPY_MODEL_f969c4036f0742b3b0cff48745bb2dcf"
            ],
            "layout": "IPY_MODEL_348c6c5e39604ce3b7cb51fa4b470b3c"
          }
        },
        "3559b4ddfd7d4b36be55ec7e702c5c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c3c6a84c19b427b87354271e2cf00d1",
            "placeholder": "​",
            "style": "IPY_MODEL_27df17739ce34e64ba8602a304f2d9f7",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "2d380eda51b043ffaf301a35e1da58fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5112f897a4c48e0836c3bf395903d8b",
            "max": 2537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1145526d0054c9c9ea9c43c208d031d",
            "value": 2537
          }
        },
        "f969c4036f0742b3b0cff48745bb2dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3497af9c7474a778218a09a9249f067",
            "placeholder": "​",
            "style": "IPY_MODEL_67538ed127274e6abe72780cd1e56820",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 54.3kB/s]"
          }
        },
        "348c6c5e39604ce3b7cb51fa4b470b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3c6a84c19b427b87354271e2cf00d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27df17739ce34e64ba8602a304f2d9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5112f897a4c48e0836c3bf395903d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1145526d0054c9c9ea9c43c208d031d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3497af9c7474a778218a09a9249f067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67538ed127274e6abe72780cd1e56820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a716c640869749cb85103cf50421a19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_447bd8184fe94fcab2f8971e2277b394",
              "IPY_MODEL_c2b14b0fdc7a41c498a70a2308a76288",
              "IPY_MODEL_7d522b98ef91458dacf3836e273f43ba"
            ],
            "layout": "IPY_MODEL_75115936b6314b18bc5d4b880adf2431"
          }
        },
        "447bd8184fe94fcab2f8971e2277b394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae74a6207c054892863de976345dedb6",
            "placeholder": "​",
            "style": "IPY_MODEL_9ed5631fd4704d04a9f1bba50ea213e5",
            "value": "Downloading spiece.model: 100%"
          }
        },
        "c2b14b0fdc7a41c498a70a2308a76288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34ad22c1bfee45aa9f0ec989a0b671d2",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb3c6cde2a444649dab15eb8738e770",
            "value": 791656
          }
        },
        "7d522b98ef91458dacf3836e273f43ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_881ce383b2034db1bfb642ae214501f1",
            "placeholder": "​",
            "style": "IPY_MODEL_a17410b871f54fbab8ee00a9a96f532a",
            "value": " 792k/792k [00:00&lt;00:00, 12.6MB/s]"
          }
        },
        "75115936b6314b18bc5d4b880adf2431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae74a6207c054892863de976345dedb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed5631fd4704d04a9f1bba50ea213e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34ad22c1bfee45aa9f0ec989a0b671d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb3c6cde2a444649dab15eb8738e770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "881ce383b2034db1bfb642ae214501f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17410b871f54fbab8ee00a9a96f532a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9abd392d98c4303895e2dfa215cdc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab3d74aebbd34849bd7cbf315623e3e9",
              "IPY_MODEL_61c5e5ea65c34949a08fa207ff84b6e1",
              "IPY_MODEL_7c49e07ca53f45f59dfc77478a8673cb"
            ],
            "layout": "IPY_MODEL_d5f2745c69a74fcfb504c6cf3c7834ab"
          }
        },
        "ab3d74aebbd34849bd7cbf315623e3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c1abbc75b446a8ac8853ae3015b677",
            "placeholder": "​",
            "style": "IPY_MODEL_d0665c2151f54451b8a42372e08fa693",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "61c5e5ea65c34949a08fa207ff84b6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65a62cb64ae8495894a43a769d1629c2",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90cea8eb2fda480cb7694cd08327c7a2",
            "value": 2424064
          }
        },
        "7c49e07ca53f45f59dfc77478a8673cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b1f3ac049b446e9b7b33089a76b7be1",
            "placeholder": "​",
            "style": "IPY_MODEL_17d4b029a7404a1893758b4d41cb1af1",
            "value": " 2.42M/2.42M [00:01&lt;00:00, 2.30MB/s]"
          }
        },
        "d5f2745c69a74fcfb504c6cf3c7834ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27c1abbc75b446a8ac8853ae3015b677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0665c2151f54451b8a42372e08fa693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65a62cb64ae8495894a43a769d1629c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90cea8eb2fda480cb7694cd08327c7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b1f3ac049b446e9b7b33089a76b7be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d4b029a7404a1893758b4d41cb1af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35a2a1b0495c450486000b197941d7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e08a098d26724ef283589bcc26be24df",
              "IPY_MODEL_1f566808e9b848e8891c6d82b8299144",
              "IPY_MODEL_2f7cc90bf3084fdeba5a0b400a0de0a5"
            ],
            "layout": "IPY_MODEL_14ac573e78b04cdaa3e5d02d113c0bcb"
          }
        },
        "e08a098d26724ef283589bcc26be24df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ebf7940b5e4121beb14abd31e6c43c",
            "placeholder": "​",
            "style": "IPY_MODEL_31c01c37ce9a40a6bcf256fede963ae4",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "1f566808e9b848e8891c6d82b8299144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1606d449ea74f30a5ec8868cdaddb86",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f9609d55332949a19b298088c462beed",
            "value": 2201
          }
        },
        "2f7cc90bf3084fdeba5a0b400a0de0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_964de911c2174d86b7d9e0c41f23731d",
            "placeholder": "​",
            "style": "IPY_MODEL_d2360e422996484a855de2fbe0123765",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 146kB/s]"
          }
        },
        "14ac573e78b04cdaa3e5d02d113c0bcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ebf7940b5e4121beb14abd31e6c43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c01c37ce9a40a6bcf256fede963ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1606d449ea74f30a5ec8868cdaddb86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9609d55332949a19b298088c462beed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "964de911c2174d86b7d9e0c41f23731d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2360e422996484a855de2fbe0123765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26a0b27be62c4401b41935eb69bbf50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16448ff91976448182b8d9d77e4c817b",
              "IPY_MODEL_be56a6274b3b40bdba1361ab7fef20ea",
              "IPY_MODEL_6d2c0da1847f4af6be62e45fb1e837b3"
            ],
            "layout": "IPY_MODEL_779027e617f0467881f566b43ee938a6"
          }
        },
        "16448ff91976448182b8d9d77e4c817b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492f1448b2a54ae3a73b894b730b95ca",
            "placeholder": "​",
            "style": "IPY_MODEL_fea0bd438738457ab56b8d292ef90eff",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "be56a6274b3b40bdba1361ab7fef20ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b18b2849e5cb4c54a63b168482e15f5b",
            "max": 1404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24fa83f2329242eabab54c97dc72f254",
            "value": 1404
          }
        },
        "6d2c0da1847f4af6be62e45fb1e837b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4012983cb7e345738d42c8e50b2aaeb2",
            "placeholder": "​",
            "style": "IPY_MODEL_eff17c418fe54d5aa14f9650c86a1d7c",
            "value": " 1.40k/1.40k [00:00&lt;00:00, 101kB/s]"
          }
        },
        "779027e617f0467881f566b43ee938a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "492f1448b2a54ae3a73b894b730b95ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fea0bd438738457ab56b8d292ef90eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b18b2849e5cb4c54a63b168482e15f5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24fa83f2329242eabab54c97dc72f254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4012983cb7e345738d42c8e50b2aaeb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff17c418fe54d5aa14f9650c86a1d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f54e57c8602f41d9975fb45e8a7bb5e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_573d69626d3c4aaeaa10de96291013cd",
              "IPY_MODEL_6b4057fb755e4bb1b639f3590914770e",
              "IPY_MODEL_431b60fc493b4f699e3cbc541f114e21"
            ],
            "layout": "IPY_MODEL_e266e21068074c6687736a85051179b6"
          }
        },
        "573d69626d3c4aaeaa10de96291013cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcee26a72f554bf495275d4ae8da1660",
            "placeholder": "​",
            "style": "IPY_MODEL_03d9ce29b9c74c248301e8c681548681",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "6b4057fb755e4bb1b639f3590914770e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07df3b6eab564baca92ae334dd307960",
            "max": 990345061,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3653923143c34a468069e700fcd2d665",
            "value": 990345061
          }
        },
        "431b60fc493b4f699e3cbc541f114e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d5a48d1f12456688df070b595aef2d",
            "placeholder": "​",
            "style": "IPY_MODEL_7f1605192a074c7d88a6f3f13d978186",
            "value": " 990M/990M [00:13&lt;00:00, 87.7MB/s]"
          }
        },
        "e266e21068074c6687736a85051179b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcee26a72f554bf495275d4ae8da1660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03d9ce29b9c74c248301e8c681548681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07df3b6eab564baca92ae334dd307960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3653923143c34a468069e700fcd2d665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3d5a48d1f12456688df070b595aef2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1605192a074c7d88a6f3f13d978186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "333fedcd448f4ed2847b6fe3cdefef33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1cda39d7106a4586bbf24740d9d45ece",
              "IPY_MODEL_3fb55e9a76084f7d998a389caa6c2a33",
              "IPY_MODEL_f2a39b648d804c008bd49258023a921c"
            ],
            "layout": "IPY_MODEL_16f90536f0a441059277075a268f03a3"
          }
        },
        "1cda39d7106a4586bbf24740d9d45ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e29803cc2034f5caa750bcae4b462aa",
            "placeholder": "​",
            "style": "IPY_MODEL_09b1b2cba7384f06b87a31e89a89a879",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "3fb55e9a76084f7d998a389caa6c2a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29e9c5089dfc49e2b1ee7fb6124a52ab",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91b30903f4a349ee88812007953b9c70",
            "value": 147
          }
        },
        "f2a39b648d804c008bd49258023a921c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9c75ba8a49e4276b916fd16254edf2b",
            "placeholder": "​",
            "style": "IPY_MODEL_528ec5fabacc4260b804dba7b9ede325",
            "value": " 147/147 [00:00&lt;00:00, 3.72kB/s]"
          }
        },
        "16f90536f0a441059277075a268f03a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e29803cc2034f5caa750bcae4b462aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b1b2cba7384f06b87a31e89a89a879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29e9c5089dfc49e2b1ee7fb6124a52ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b30903f4a349ee88812007953b9c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9c75ba8a49e4276b916fd16254edf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "528ec5fabacc4260b804dba7b9ede325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d8e14814a704086bb8601809ba43f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15760ab1562040a0bd1a75f2739d2af9",
              "IPY_MODEL_5f1c30eb66814430b183beb33e3f3d78",
              "IPY_MODEL_05c75ad5201748d6bf4f625841c97ef5"
            ],
            "layout": "IPY_MODEL_2bb746f61c7242dba2361357109b2cb0"
          }
        },
        "15760ab1562040a0bd1a75f2739d2af9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7004235a5a734e2291ce438b39cfc8bb",
            "placeholder": "​",
            "style": "IPY_MODEL_787545fc066e469eafec50ebf7b31ea4",
            "value": "Map:  99%"
          }
        },
        "5f1c30eb66814430b183beb33e3f3d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333d64909f094b1c88e84a7ae6ada70e",
            "max": 10647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_415027eadecf4873b0e5f17073c2f11a",
            "value": 10647
          }
        },
        "05c75ad5201748d6bf4f625841c97ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8961bde03ad94d098a738405e01f53da",
            "placeholder": "​",
            "style": "IPY_MODEL_336b45364085492fb99eae49ae11e3d6",
            "value": " 10556/10647 [00:10&lt;00:00, 1234.69 examples/s]"
          }
        },
        "2bb746f61c7242dba2361357109b2cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "7004235a5a734e2291ce438b39cfc8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "787545fc066e469eafec50ebf7b31ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "333d64909f094b1c88e84a7ae6ada70e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "415027eadecf4873b0e5f17073c2f11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8961bde03ad94d098a738405e01f53da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "336b45364085492fb99eae49ae11e3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39722da02d8d4287b37127b81cb1f7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8012cfe4af84cd685f391dc88eab083",
              "IPY_MODEL_4e6e4193979b47c490417120ae144dbd",
              "IPY_MODEL_b082da49d4bf4547bad7285a48380c8c"
            ],
            "layout": "IPY_MODEL_412b99b0cc6e421788c2f7b0cff518a8"
          }
        },
        "b8012cfe4af84cd685f391dc88eab083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eee6d216ccdd42978f7540fd578cc7e2",
            "placeholder": "​",
            "style": "IPY_MODEL_9b6154a8fb774c14a964614a03bc664e",
            "value": "Map:  99%"
          }
        },
        "4e6e4193979b47c490417120ae144dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ceadebf500c41119860acbc8c91336c",
            "max": 10647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31d96e8c627e43b4aa633dbcb5985cbb",
            "value": 10647
          }
        },
        "b082da49d4bf4547bad7285a48380c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f8ee5803d24570843d643f8a948f88",
            "placeholder": "​",
            "style": "IPY_MODEL_38e80ea1d2b54d6887389a1f062530bf",
            "value": " 10573/10647 [00:10&lt;00:00, 1106.28 examples/s]"
          }
        },
        "412b99b0cc6e421788c2f7b0cff518a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "eee6d216ccdd42978f7540fd578cc7e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6154a8fb774c14a964614a03bc664e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ceadebf500c41119860acbc8c91336c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d96e8c627e43b4aa633dbcb5985cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1f8ee5803d24570843d643f8a948f88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e80ea1d2b54d6887389a1f062530bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}